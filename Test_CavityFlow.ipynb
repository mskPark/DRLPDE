{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Cavity Flow\n",
    "###\n",
    "### In trying to obtain the proper flow pattern, the neural network has to make a significant 'discovery'\n",
    "### It wants to learn 0 everywhere except at the top lid, and be like 'can't learn any better than this'\n",
    "### And so I think the trained result is stochastic -> There is some chance that it will learn in the training session\n",
    "### The longer the training session, the more likely the NN will end up there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Save model and/or Load model ##############\n",
    "\n",
    "savemodel = 'CavityFlow'\n",
    "loadmodel = ''\n",
    "\n",
    "# Physical Dimension\n",
    "x_dim = 2\n",
    "output_dim = 2\n",
    "\n",
    "# Steady   or Unsteady\n",
    "# Elliptic or Parabolic\n",
    "is_unsteady = False\n",
    "input_dim = x_dim + is_unsteady\n",
    "\n",
    "################# PDE Coefficients ########################\n",
    "\n",
    "lidspeed = 1.0\n",
    "mu = 1.0\n",
    "\n",
    "def bdry_con_wall(X):\n",
    "    u = torch.zeros( (X.size(0), output_dim), device=X.device)\n",
    "    return u\n",
    "\n",
    "def bdry_con_lid(X):\n",
    "    u = torch.zeros( (X.size(0), output_dim), device=X.device)\n",
    "\n",
    "    u[:,0] = lidspeed\n",
    "    return u\n",
    "\n",
    "#################  Make the domain  #######################\n",
    "\n",
    "boundingbox = [ [-1,1], [-1,1] ]\n",
    "\n",
    "wall_left = {'type':'line',\n",
    "             'point': [-1,0],\n",
    "             'normal': [1,0],\n",
    "             'endpoints': [ [-1,-1], [-1,1] ],\n",
    "             'boundary_condition': bdry_con_wall }\n",
    "\n",
    "lid_top = { 'type':'line',\n",
    "             'point': [0,1],\n",
    "             'normal': [0,-1],\n",
    "             'endpoints': [ [-1,1],   [1,1]  ],\n",
    "             'boundary_condition': bdry_con_lid }\n",
    "\n",
    "wall_right= {'type':'line',\n",
    "             'point': [1, 0],\n",
    "             'normal':  [-1,0],\n",
    "             'endpoints':  [ [1,-1],   [1,1]  ],\n",
    "             'boundary_condition': bdry_con_wall }\n",
    "\n",
    "wall_bot = {'type':'line',\n",
    "             'point': [0,-1],\n",
    "             'normal': [0,1],\n",
    "             'endpoints': [ [-1,-1], [1,-1] ],\n",
    "             'boundary_condition': bdry_con_wall }\n",
    "\n",
    "list_of_dirichlet_boundaries = [wall_left, lid_top, wall_right, wall_bot ]\n",
    "list_of_periodic_boundaries =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time step\n",
    "dt = 1e-4\n",
    "\n",
    "# exit tolerance\n",
    "tol = 1e-6\n",
    "\n",
    "# Number of walkers\n",
    "num_walkers = 2**12\n",
    "num_ghost = 128\n",
    "num_batch = 2**12\n",
    "\n",
    "# Update walkers\n",
    "# Options: \n",
    "#    move -- moves walkers to one of their new locations\n",
    "#    remake -- remake walkers at each training step\n",
    "#    fixed -- keeps walkers fixed\n",
    "update_walkers = 'move'\n",
    "update_walkers_every = 1\n",
    "\n",
    "# Number of boundary points \n",
    "num_bdry = 2**10\n",
    "\n",
    "############## Training Parameters #######################\n",
    "\n",
    "# Training epochs\n",
    "num_step = 1000\n",
    "update_print_every = 500\n",
    "\n",
    "# Neural Network Architecture\n",
    "nn_depth = 60\n",
    "nn_width = 4\n",
    "\n",
    "# Weighting of losses\n",
    "lambda_bell = 1e-2/dt\n",
    "lambda_bdry = 1e0\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-2\n",
    "adam_beta = (0.9,0.999)\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncompressibleNN(torch.nn.Module):\n",
    "    \n",
    "    ### Incompressible neural network\n",
    "    ### curl operation built in\n",
    "    \n",
    "    def __init__(self, depth, width, x_dim, is_unsteady, **nn_param):\n",
    "        super(IncompressibleNN, self).__init__()\n",
    "        \n",
    "        self.x_dim = x_dim\n",
    "        self.input_dim = self.x_dim + is_unsteady\n",
    "        \n",
    "        self.dim_out = 2\n",
    "        \n",
    "        modules = []\n",
    "        modules.append(torch.nn.Linear(self.input_dim, depth))\n",
    "        for i in range(width - 1):\n",
    "            modules.append(torch.nn.Linear(depth, depth))\n",
    "            modules.append(torch.nn.Tanh())\n",
    "        modules.append(torch.nn.Linear(depth, self.dim_out))\n",
    "                       \n",
    "        self.sequential_model = torch.nn.Sequential(*modules)\n",
    "    \n",
    "    def curl(self, a, x):\n",
    "        if self.x_dim == 2:\n",
    "\n",
    "            e = torch.eye(self.x_dim, device=x.device)\n",
    "            \n",
    "            dadx = torch.autograd.grad(a, x, grad_outputs=e[0,:].repeat(a.size(0), 1), \n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "            dpdx = torch.autograd.grad(a, x, grad_outputs=e[1,:].repeat(a.size(0), 1),\n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "\n",
    "            u = torch.stack([dadx[:,1], -dadx[:,0], dpdx[:,0], dpdx[:,1]] , dim=1)\n",
    "            \n",
    "        elif self.x_dim == 3:\n",
    "            e = torch.eye(self.x_dim, device=x.device)\n",
    "\n",
    "            da0dx = torch.autograd.grad(a, x, grad_outputs=e[0,:].repeat(a.size(0), 1), \n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "            da1dx = torch.autograd.grad(a, x, grad_outputs=e[1,:].repeat(a.size(0), 1),\n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "            da2dx = torch.autograd.grad(a, x, grad_outputs=e[2,:].repeat(a.size(0), 1),\n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "\n",
    "            u = torch.stack([da2dx[:,1] - da1dx[:,2], da0dx[:,2] - da2dx[:,0], da1dx[:,0] - da0dx[:,1] ], dim=1)         \n",
    "        return u\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a = self.sequential_model(x)\n",
    "        u = self.curl(a, x)\n",
    "            \n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Domain\n",
    "class Domain:\n",
    "    ### This class defines the domain using the parameters provided\n",
    "    ### It sets up the boundingbox and each boundary\n",
    "\n",
    "    def __init__(self, is_unsteady, boundingbox, \n",
    "                list_of_dirichlet_boundaries,\n",
    "                list_of_periodic_boundaries=False):\n",
    "        \n",
    "        self.boundingbox = boundingbox\n",
    "        self.is_unsteady = is_unsteady\n",
    "\n",
    "        self.num_of_boundaries = len(list_of_dirichlet_boundaries)\n",
    "        \n",
    "        # Unpack dirichlet boundary descriptions\n",
    "        self.boundaries = []\n",
    "        for specs in list_of_dirichlet_boundaries:\n",
    "            ### 2D boundaries\n",
    "            if specs['type'] == 'line':\n",
    "                self.boundaries.append( bdry_line( point = specs['point'], \n",
    "                                                   normal = specs['normal'],\n",
    "                                                   endpoints = specs['endpoints'],\n",
    "                                                   boundary_condition = specs['boundary_condition'] ))\n",
    "            \n",
    "            if specs['type'] == 'disk':\n",
    "                self.boundaries.append( bdry_disk( centre = specs['centre'],\n",
    "                                                   radius = specs['radius'], \n",
    "                                                   boundary_condition = specs['boundary_condition'] ))\n",
    "          \n",
    "        # Unpack any periodic boundaries\n",
    "        self.periodic_boundaries = []\n",
    "        for specs in list_of_periodic_boundaries:\n",
    "            self.periodic_boundaries.append( bdry_periodic( variable = specs['variable'],\n",
    "                                                            base = specs['base'],\n",
    "                                                            top = specs['top']  ))\n",
    "\n",
    "### Boundary Classes\n",
    "\n",
    "# 2D Boundaries\n",
    "class bdry_disk:\n",
    "    ### Class structure for a 2D solid disk boundary, the domain being outside the disk\n",
    "    \n",
    "    def __init__(self, centre, radius, boundary_condition):\n",
    "        ### Centre and Radius\n",
    "        self.centre = torch.tensor( centre )\n",
    "        self.radius = radius\n",
    "\n",
    "        self.bdry_cond = boundary_condition\n",
    "        \n",
    "        self.angles = [0, 2*math.pi]\n",
    "            \n",
    "            \n",
    "    def make_bdry_pts(self, num_bdry, boundingbox, other_bdrys):\n",
    "        ### Make random points along the boundary\n",
    "        \n",
    "        #theta = 2*math.pi*torch.rand(num_bdry)\n",
    "        theta = torch.linspace(0,2*math.pi, 2**7)\n",
    "        \n",
    "        #rad_theta = torch.cartesian_prod(self.radius*torch.sqrt(torch.linspace(0,1, 2**4)),\n",
    "        #                                 torch.linspace(0,2*math.pi, 2**6))\n",
    "\n",
    "        Xbdry = torch.stack((self.radius*torch.cos(theta) + self.centre[0],\n",
    "                                 self.radius*torch.sin(theta) + self.centre[1]),dim=1 )\n",
    "\n",
    "        #Xbdry = torch.stack( (rad_theta[:,0]*torch.cos(rad_theta[:,1]) + self.centre[0],\n",
    "        #                      rad_theta[:,0]*torch.sin(rad_theta[:,1]) + self.centre[1]), dim=1)\n",
    "\n",
    "        \n",
    "        #Xbdry = torch.cat( ( Spacebdry, \n",
    "        #                     boundingbox[2][1]*torch.rand(num_bdry,1),\n",
    "        #                     boundingbox[3][1]*torch.rand(num_bdry,1),\n",
    "        #                     boundingbox[4][1]*torch.rand(num_bdry,1),), dim=1)\n",
    "\n",
    "    \n",
    "        ### Check if outside other bdrys\n",
    "        ### and remake bdry points\n",
    "        outside = torch.zeros(Xbdry.size(0), dtype=torch.bool)\n",
    "\n",
    "        for bdry in other_bdrys:\n",
    "            outside += bdry.dist_to_bdry(Xbdry) < 0\n",
    "        \n",
    "        if any(outside):\n",
    "            Xbdry[outside,:] = self.make_bdry_pts(torch.sum(outside), boundingbox, is_unsteady, other_bdrys)\n",
    "\n",
    "        return Xbdry\n",
    "            \n",
    "    def dist_to_bdry(self, X):\n",
    "        ### Signed distance to boundary\n",
    "        ### positive = inside domain\n",
    "        ### negative = outside domain\n",
    "\n",
    "        distance = ( torch.norm(X[:,:2] - self.centre.to(X.device),dim=1) - self.radius )\n",
    "        return distance\n",
    "    \n",
    "class bdry_line:\n",
    "    ### Class structure for a line boundary\n",
    "    ###       normal vector points inside\n",
    "    \n",
    "    def __init__(self, point, normal, endpoints, boundary_condition):\n",
    "        self.point = torch.tensor(  point )\n",
    "        self.normal = torch.tensor( normal )\n",
    "        self.constant = -sum( self.normal*self.point )\n",
    "        \n",
    "        self.bdry_cond = boundary_condition\n",
    "        \n",
    "        self.endpoints = torch.tensor(endpoints)\n",
    "        \n",
    "    def make_bdry_pts(self, num_bdry, boundingbox, other_bdrys):\n",
    "           \n",
    "        #Spacebdry = ( self.endpoints[1] - self.endpoints[0] )*torch.rand((num_bdry,1)) + self.endpoints[0]\n",
    "        Xbdry = ( self.endpoints[1] - self.endpoints[0] )*torch.linspace(0,1, num_bdry)[:,None] + self.endpoints[0]\n",
    "        \n",
    "        #Xbdry = torch.cat( ( Spacebdry, \n",
    "        #                       boundingbox[2][1]*torch.rand(num_bdry,1),\n",
    "        #                       boundingbox[3][1]*torch.rand(num_bdry,1),\n",
    "        #                       boundingbox[4][1]*torch.rand(num_bdry,1),), dim=1)\n",
    "        \n",
    "        ### Check if outside other bdrys\n",
    "        ### and remake bdry points\n",
    "        #outside = torch.zeros(Xbdry.size(0), dtype=torch.bool)\n",
    "\n",
    "        #for bdry in other_bdrys:\n",
    "        #    outside += bdry.dist_to_bdry(Xbdry[:,:2]) < 0\n",
    "        \n",
    "        #if any(outside):\n",
    "        #    Xbdry[outside,:] = self.make_bdry_pts(torch.sum(outside), boundingbox, is_unsteady, other_bdrys)\n",
    "\n",
    "        return Xbdry\n",
    "    \n",
    "    def dist_to_bdry(self, X):\n",
    "        ### Signed distance to boundary\n",
    "        ### positive = inside domain\n",
    "        ### negative = outside domain\n",
    "        distance = torch.sum( self.normal.to(X.device)*X[:,:2], dim=1) + self.constant\n",
    "        \n",
    "        return distance\n",
    "\n",
    "class Walker_Data(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, num_walkers, boundingbox, boundaries):\n",
    "        \n",
    "        Xold = generate_interior_points(num_walkers, boundingbox, boundaries)\n",
    "        #region = close_to_region(Xold)\n",
    "        \n",
    "        self.location = Xold\n",
    "        self.num_pts = num_walkers\n",
    "        #self.region = region\n",
    "        \n",
    "    def __len__(self):\n",
    "        ### How many data points are there?\n",
    "        return self.num_pts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ### Gets one sample of data\n",
    "        ### \n",
    "        return self.location[index,:], index\n",
    "        \n",
    "class Boundary_Data(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, num_bdry, boundingbox, boundaries):\n",
    "        \n",
    "        Xbdry, Ubdry = generate_boundary_points(num_bdry, boundingbox, boundaries)\n",
    "        \n",
    "        self.location = Xbdry\n",
    "        self.num_pts = Xbdry.size(0)\n",
    "        self.value = Ubdry\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_pts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.location[index,:], self.value[index,:]    \n",
    "\n",
    "class Initial_Data(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, num_init, boundingbox, boundaries):\n",
    "        \n",
    "        Xinit = generate_interior_points(num_init, boundingbox, boundaries)\n",
    "        Xinit[:,2] = 0\n",
    "\n",
    "        self.location = Xinit\n",
    "        self.num_pts = num_init\n",
    "        self.value = initial_con(Xinit)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_pts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.location[index,:], self.value[index,:]    \n",
    "\n",
    "def generate_interior_points(num_walkers, boundingbox, boundaries):\n",
    "    ### Generate points inside the domain\n",
    "\n",
    "    X = torch.empty( (num_walkers, len(boundingbox)) )\n",
    "\n",
    "    for ii in range(len(boundingbox)):\n",
    "        X[:,ii] = (boundingbox[ii][1] - boundingbox[ii][0])*torch.rand( (num_walkers) ) + boundingbox[ii][0]\n",
    "        \n",
    "        #Parameters are given in log scale, rescale back\n",
    "        #if ii > 2:\n",
    "        #    X[:,ii] = 10**X[:,ii]\n",
    "\n",
    "    outside = torch.zeros( X.size(0), dtype=torch.bool)\n",
    "    for bdry in boundaries:\n",
    "        outside += bdry.dist_to_bdry(X) < 0\n",
    "    \n",
    "    if any(outside):\n",
    "        X[outside,:] = generate_interior_points(torch.sum(outside), boundingbox, boundaries)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def generate_boundary_points(num_bdry, boundingbox, boundaries):\n",
    "    ### Generate points along the boundary\n",
    "    \n",
    "    points_per_bdry = []\n",
    "    utrue_per_bdry = []\n",
    "    \n",
    "    # Generate num_bdry points for each boundary\n",
    "    for ii in range(len(boundaries)):\n",
    "        bdry = boundaries[ii]\n",
    "        other_bdrys = boundaries[:ii] + boundaries[ii+1:]\n",
    "\n",
    "        # Generate boundary points\n",
    "        X_in_bdry =  bdry.make_bdry_pts(num_bdry, boundingbox, other_bdrys)\n",
    "        U_in_bdry = bdry.bdry_cond(X_in_bdry)\n",
    "\n",
    "        points_per_bdry.append( X_in_bdry )\n",
    "        utrue_per_bdry.append( U_in_bdry )\n",
    "\n",
    "    Xbdry = torch.cat( points_per_bdry, dim=0)\n",
    "    Ubdry_true = torch.cat( utrue_per_bdry, dim=0)\n",
    "\n",
    "    # Sample from above boundary points\n",
    "    #indices = torch.multinomial( torch.arange( len(boundaries)*num_bdry, dtype=torch.float ), num_bdry)\n",
    "    \n",
    "    #Xbdry = Xbdry[indices,:]\n",
    "    #Ubdry_true = Ubdry_true[indices,:]\n",
    "    \n",
    "    return Xbdry, Ubdry_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization\n",
    "\n",
    "there_are_boundaries = bool(list_of_dirichlet_boundaries)\n",
    "\n",
    "nn_param = {'depth': nn_depth,\n",
    "            'width': nn_width,\n",
    "            'x_dim': x_dim,\n",
    "            'is_unsteady': is_unsteady,\n",
    "            'output_dim': output_dim,\n",
    "            }\n",
    "                \n",
    "################ Preparing the model #################\n",
    "\n",
    "#print(\"Initializing the model\")\n",
    "\n",
    "### Make boundaries defining the domain\n",
    "MyDomain = Domain(is_unsteady, boundingbox, \n",
    "                  list_of_dirichlet_boundaries,\n",
    "                  list_of_periodic_boundaries)\n",
    "\n",
    "### Initialize the Model\n",
    "#model = IncompressibleNN(**nn_param) #.to(dev)\n",
    "import DRLPDE_nn\n",
    "\n",
    "model = DRLPDE_nn.IncompressibleNN(**nn_param).to(dev)\n",
    "\n",
    "mseloss = torch.nn.MSELoss(reduction = 'mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                        lr=learning_rate, \n",
    "                        betas=adam_beta, \n",
    "                        weight_decay=weight_decay)\n",
    "\n",
    "### Create Walkers and Boundary points and Organize into DataLoader\n",
    "RWalkers = Walker_Data(num_walkers, boundingbox, MyDomain.boundaries)\n",
    "RWalkers_batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if update_walkers == 'move':\n",
    "    move_RWalkers = torch.zeros_like(RWalkers.location)\n",
    "\n",
    "if there_are_boundaries:\n",
    "    BPoints = Boundary_Data(num_bdry, boundingbox, MyDomain.boundaries)\n",
    "    BPoints_batch = torch.utils.data.DataLoader(BPoints, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if is_unsteady:\n",
    "    IPoints = Initial_Data(num_init, boundingbox, MyDomain.boundaries)\n",
    "    IPoints_batch = torch.utils.data.DataLoader(IPoints, batch_size=num_batch, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NS(X, model, x_dim, boundaries, num_batch, num_ghost, tol):\n",
    "    \n",
    "    ### Evaluate model\n",
    "    Uold = model(X)\n",
    "    #Uold = UdPold[:,:2]\n",
    "    #dPold = UdPold[:,2:]\n",
    "\n",
    "    ### Move walkers\n",
    "    # Increase dimension of the brownian motion\n",
    "    #Space_new = X[:,:2].repeat(num_ghost,1) - dt*Uold.detach().repeat(num_ghost,1) + np.sqrt(2*dt*mu)*torch.randn((num_batch*num_ghost, x_dim), device=X.device, requires_grad=True)\n",
    "    #Time_new = X[:,2,None].repeat(num_ghost,1) - dt\n",
    "    #Param_new = X[:,x_dim+1:].repeat(num_ghost,1)\n",
    "\n",
    "    #Xnew = torch.cat( (Space_new, Time_new, Param_new), dim=1 )\n",
    "    #Xnew = torch.cat( (Space_new, Time_new), dim=1 )\n",
    "\n",
    "    Xnew = X.repeat(num_ghost,1) - dt*Uold.detach().repeat(num_ghost,1) + np.sqrt(2*dt*mu)*torch.randn((num_batch*num_ghost, x_dim), device=X.device, requires_grad=True)\n",
    "\n",
    "    Unew = model(Xnew)\n",
    "\n",
    "    ### Calculate exits and re-evaluate points\n",
    "    Xnew, Unew, outside = exit_condition(X.repeat(num_ghost,1), Xnew, Unew, boundaries, tol)\n",
    "\n",
    "    #Unew = UdPnew[:,:2].reshape(num_ghost, num_batch, 2).mean(0).detach()\n",
    "    #dPnew = UdPnew[:,2:].reshape(num_ghost, num_batch, 2).mean(0).detach()\n",
    "\n",
    "    Unew = Unew.reshape(num_ghost, num_batch,2).mean(0).detach()\n",
    "\n",
    "    return Xnew, Uold, Unew, outside[:num_batch]\n",
    "\n",
    "def exit_condition(Xold, Xnew, Unew, boundaries, tol):\n",
    "    ### Calculate exit conditions\n",
    "    outside = torch.zeros( Xnew.size(0), dtype=torch.bool, device=Xnew.device)\n",
    "    \n",
    "    for bdry in boundaries:\n",
    "        outside_bdry = bdry.dist_to_bdry(Xnew) < 0\n",
    "        if torch.sum(outside_bdry) > 0:\n",
    "            ### Bisection to get close to exit location up to tolerance tol\n",
    "            \n",
    "            Xnew[outside_bdry,:] = find_bdry_exit(Xold[outside_bdry,:], Xnew[outside_bdry,:], bdry, tol)\n",
    "            #UdPnew[outside_bdry,:2] = bdry.bdry_cond(Xnew[outside_bdry,:])\n",
    "            Unew[outside_bdry,:2] = bdry.bdry_cond(Xnew[outside_bdry,:])\n",
    "\n",
    "        outside += outside_bdry\n",
    "\n",
    "    ### Check for time = 0\n",
    "    ### Note: This prioritizes time exit over bdry exit\n",
    "    ### Question: \n",
    "    ###     Should we take a point at the initial time (by projecting or something)\n",
    "    ###     or is within tol good enough?\n",
    "    #hit_initial = Xnew[:,2] < 0\n",
    "    #Xnew[hit_initial,:] = find_time_exit(Xold[hit_initial,:], Xnew[hit_initial,:], tol)\n",
    "    #Unew[hit_initial,:] = initial_con(Xnew[hit_initial,:])\n",
    "\n",
    "    #outside += hit_initial\n",
    "\n",
    "    return Xnew, Unew, outside\n",
    "\n",
    "def find_bdry_exit(Xold, Xnew, bdry, tol):\n",
    "    ### Bisection algorithm to find the exit between Xnew and Xold up to a tolerance \n",
    "    \n",
    "    Xmid = (Xnew + Xold)/2\n",
    "    \n",
    "    dist = bdry.dist_to_bdry(Xmid)\n",
    "    \n",
    "    # above tolerance = inside\n",
    "    # below tolerance = outside\n",
    "    above_tol = dist > tol\n",
    "    below_tol = dist < -tol\n",
    "    \n",
    "    if torch.sum(above_tol + below_tol) > 0:\n",
    "        Xnew[below_tol,:] = Xmid[below_tol,:]\n",
    "        Xold[above_tol,:] = Xmid[above_tol,:]\n",
    "        \n",
    "        Xmid[above_tol + below_tol,:] = find_bdry_exit(Xold[above_tol + below_tol,:], Xnew[above_tol + below_tol,:], bdry, tol)\n",
    "\n",
    "    return Xmid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train from Solution\n",
    "\n",
    "#from scipy.io import loadmat\n",
    "\n",
    "#pretrain_step = 0\n",
    "#numplotpts1d = 128\n",
    "#numplotpts = numplotpts1d**2\n",
    "\n",
    "#xg = torch.cartesian_prod(torch.linspace(-1.0, 1.0, numplotpts1d, device=dev), \n",
    "#                          torch.linspace(-1.0, 1.0, numplotpts1d, device=dev))\n",
    "\n",
    "#contents = loadmat('tools/Cavity_Flow_2D_Data_128x128.mat')\n",
    "#u1_true = np.transpose(contents['u'])\n",
    "#u2_true = np.transpose(contents['v'])\n",
    "#utrue = torch.tensor( np.concatenate( (u1_true.reshape(numplotpts,1), u2_true.reshape(numplotpts,1)), axis=1), device=dev )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for step in range(pretrain_step):\n",
    "#    ug = model(xg.requires_grad_(True))\n",
    "#    loss = mseloss(ug, utrue)\n",
    "#    loss.backward()\n",
    "#    optimizer.step()\n",
    "#    optimizer.zero_grad()\n",
    "\n",
    "#torch.save(model.state_dict(), \"savedmodels/\" + savemodel + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors in first epoch\n",
      "Approx time: 45 minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m Xold \u001b[39m=\u001b[39m Xold\u001b[39m.\u001b[39mto(dev)\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#Xold = Xold.requires_grad_(True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Evaluate at old location and Move walkers\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Xnew, Uold, Unew, outside \u001b[39m=\u001b[39m evaluate_NS(Xold, model, x_dim, MyDomain\u001b[39m.\u001b[39;49mboundaries, num_batch, num_ghost, tol)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Calculate loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#loss = lambda_bell*mseloss(Uold + (dt/2)*dPold, Unew - (dt/2)*dPnew)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m lambda_bell\u001b[39m*\u001b[39mmseloss(Uold, Unew)\n",
      "\u001b[1;32m/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb Cell 11\u001b[0m in \u001b[0;36mevaluate_NS\u001b[0;34m(X, model, x_dim, boundaries, num_batch, num_ghost, tol)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#Uold = UdPold[:,:2]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#dPold = UdPold[:,2:]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#Xnew = torch.cat( (Space_new, Time_new, Param_new), dim=1 )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#Xnew = torch.cat( (Space_new, Time_new), dim=1 )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m Xnew \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mrepeat(num_ghost,\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m dt\u001b[39m*\u001b[39mUold\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mrepeat(num_ghost,\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mdt\u001b[39m*\u001b[39mmu)\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mrandn((num_batch\u001b[39m*\u001b[39mnum_ghost, x_dim), device\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdevice, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Unew \u001b[39m=\u001b[39m model(Xnew)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m### Calculate exits and re-evaluate points\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/Test_CavityFlow.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m Xnew, Unew, outside \u001b[39m=\u001b[39m exit_condition(X\u001b[39m.\u001b[39mrepeat(num_ghost,\u001b[39m1\u001b[39m), Xnew, Unew, boundaries, tol)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Research/DRLPDE/DRLPDE_nn.py:142\u001b[0m, in \u001b[0;36mIncompressibleNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 142\u001b[0m     a \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msequential_model(x)\n\u001b[1;32m    143\u001b[0m     u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurl(a, x)\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m u\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "################ Training the model #################\n",
    "\n",
    "#print(\"Training has begun\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "### Run the training loop\n",
    "\n",
    "for step in range(num_step):\n",
    "\n",
    "    # Random Walkers - do in batches\n",
    "    for Xold, index in RWalkers_batch:\n",
    "\n",
    "        # Send to GPU and set requires grad flag\n",
    "        Xold = Xold.to(dev).requires_grad_(True)\n",
    "        #Xold = Xold.requires_grad_(True)\n",
    "\n",
    "        # Evaluate at old location and Move walkers\n",
    "        Xnew, Uold, Unew, outside = evaluate_NS(Xold, model, x_dim, MyDomain.boundaries, num_batch, num_ghost, tol)\n",
    "\n",
    "        # Calculate loss\n",
    "        #loss = lambda_bell*mseloss(Uold + (dt/2)*dPold, Unew - (dt/2)*dPnew)\n",
    "        loss = lambda_bell*mseloss(Uold, Unew)\n",
    "        #print(loss.data.cpu().numpy())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # No importance sampling. Walkers just move\n",
    "        # If moving walkers save the first ghost walker\n",
    "        if update_walkers == 'move':\n",
    "            if any(outside):\n",
    "                Xnew[:num_batch,:][outside,:] = generate_interior_points(torch.sum(outside),boundingbox,MyDomain.boundaries).to(dev)\n",
    "            move_RWalkers[index,:] = Xnew[:num_batch].detach().cpu()\n",
    "\n",
    "\n",
    "    # Boundary Points - do in batches\n",
    "    for Xbdry, Ubtrue in BPoints_batch:\n",
    "        Xbdry = Xbdry.to(dev).requires_grad_(True)\n",
    "        #Xbdry = Xbdry.requires_grad_(True)\n",
    "        Ubtrue = Ubtrue.to(dev).detach()\n",
    "        #Ubtrue = Ubtrue.detach()\n",
    "        Ubdry = model(Xbdry)\n",
    "        loss = lambda_bdry*mseloss(Ubdry[:,:2], Ubtrue)\n",
    "        #print(loss.data.cpu().numpy())\n",
    "        loss.backward()\n",
    "\n",
    "    # Initial Condition Points - do in batches\n",
    "    #if is_unsteady:\n",
    "    #    for Xinit, Uinittrue in IPoints_batch:\n",
    "    #        Xinit = Xinit.to(dev).requires_grad_(True)\n",
    "    #        #Xinit = Xinit.requires_grad_(True)\n",
    "    #        Uinittrue = Uinittrue.to(dev).detach()\n",
    "    #        #Ubtrue = Uinittrue.detach()\n",
    "    #        Uinit = model(Xinit)\n",
    "    #        loss = lambda_init*mseloss(Uinit, Uinittrue)\n",
    "    #        loss.backward()\n",
    "\n",
    "    # Make optimization step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Update walkers\n",
    "\n",
    "    if (step+1) % update_walkers_every == 0:\n",
    "        if update_walkers == 'move':\n",
    "            RWalkers.location = move_RWalkers\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "        #BPoints.location, BPoints.value = generate_boundary_points(num_bdry, boundingbox, MyDomain.boundaries)\n",
    "        #BPoints_batch = torch.utils.data.DataLoader(BPoints, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "        #IPoints.location = generate_interior_points(num_init, boundingbox, MyDomain.boundaries)\n",
    "        #IPoints.location[:,2] = 0\n",
    "        #IPoints.value = initial_con(IPoints.location)\n",
    "        #IPoints_batch = torch.utils.data.DataLoader(IPoints, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "    # Print statements\n",
    "    if step == 0:\n",
    "        print('No errors in first epoch')\n",
    "        current_time = time.time()\n",
    "        print('Approx time: {:.0f} minutes'.format((current_time - start_time)*num_step/60))\n",
    "    if (step+1) % update_print_every == 0:\n",
    "        current_time = time.time()\n",
    "        print('step = {0}/{1}, {2:2.3f} s/step, time-to-go:{3:2.0f} min'.format(\n",
    "                step+1, num_step, (current_time - start_time) / (step + 1), \n",
    "            (current_time - start_time) / (step + 1) * (num_step - step - 1)/60))\n",
    "\n",
    "# Save model as pickle file\n",
    "\n",
    "torch.save(model.state_dict(), \"savedmodels/\" + savemodel + \".pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
