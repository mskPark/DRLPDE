{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "### Use cuda\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "torch.set_default_dtype(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solver Parameters\n",
    "\n",
    "############## Walker and Boundary Parameters ############\n",
    "\n",
    "savemodel = 'flowpastdisk_test'\n",
    "\n",
    "# Time step\n",
    "dt = 1e-4\n",
    "\n",
    "# exit tolerance\n",
    "tol = 1e-6\n",
    "\n",
    "# Number of walkers\n",
    "num_walkers = 2**12\n",
    "num_ghost = 256\n",
    "num_batch = 2**12\n",
    "\n",
    "# Update walkers\n",
    "# Options: \n",
    "#    move -- moves walkers to one of their new locations\n",
    "#    remake -- remake walkers at each training step\n",
    "#    fixed -- keeps walkers fixed\n",
    "update_walkers = 'move'\n",
    "update_walkers_every = 1\n",
    "\n",
    "# Number of boundary points \n",
    "num_bdry = 2**10\n",
    "\n",
    "# Number of initial condition points\n",
    "#num_init = 2**12\n",
    "\n",
    "############## Training Parameters #######################\n",
    "\n",
    "# Training epochs\n",
    "num_step = 1000\n",
    "update_print_every = 500\n",
    "\n",
    "# Neural Network Architecture\n",
    "nn_depth = 60\n",
    "nn_width = 4\n",
    "\n",
    "# Weighting of losses\n",
    "lambda_bell = 1e-2/dt\n",
    "lambda_bdry = 1e2\n",
    "#lambda_init = 0 #1e0\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-2\n",
    "adam_beta = (0.9,0.999)\n",
    "weight_decay = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Flow Past Disk \n",
    "\n",
    "# Physical Dimension\n",
    "x_dim = 2\n",
    "output_dim = 2\n",
    "is_unsteady=False\n",
    "\n",
    "# Steady   or Unsteady\n",
    "# Elliptic or Parabolic\n",
    "\n",
    "input_dim = x_dim\n",
    "\n",
    "L_height = 0.5\n",
    "mu = 1.0\n",
    "\n",
    "v0 = 5.0 #1.513787 original value\n",
    "\n",
    "def bdry_con(X):\n",
    "    u = torch.zeros( (X.size(0), output_dim), device=X.device)\n",
    "    return u\n",
    "\n",
    "def inlet_con(X):\n",
    "    u = torch.zeros( (X.size(0), output_dim), device=X.device)\n",
    "    u[:,0] = v0*(L_height - X[:,1])*(L_height + X[:,1])/(L_height**2)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "#boundingbox = [ [0, 5*L_height], [-L_height,L_height], [0, Tmax], [Viscosity_min, Viscosity_max], [Inputspeed_min, Inputspeed_max] ]\n",
    "boundingbox = [ [0, 5*L_height], [-L_height,L_height]]\n",
    "\n",
    "bdry1 = {   'type':'disk',\n",
    "            'centre': [L_height,0],\n",
    "            'radius': L_height/3,\n",
    "            'boundary_condition':bdry_con }\n",
    "\n",
    "wall_left = {'type':'line',\n",
    "             'point': [0, -L_height],\n",
    "             'normal': [1,0],\n",
    "             'endpoints': [ [0, -L_height], [0, L_height] ],\n",
    "             'boundary_condition': inlet_con }\n",
    "\n",
    "wall_top = { 'type':'line',\n",
    "             'point': [0, L_height],\n",
    "             'normal':  [0,-1],\n",
    "             'endpoints': [ [0, L_height], [5*L_height, L_height] ],\n",
    "             'boundary_condition': bdry_con }\n",
    "\n",
    "wall_bot = {'type':'line',\n",
    "             'point': [0,-L_height],\n",
    "             'normal': [0, 1],\n",
    "             'endpoints': [ [0, -L_height], [5*L_height, -L_height] ],\n",
    "             'boundary_condition': bdry_con }\n",
    "\n",
    "wall_right = {'type':'line',\n",
    "             'point': [5*L_height, -L_height],\n",
    "             'normal': [-1,0],\n",
    "             'endpoints': [ [5*L_height, -L_height], [5*L_height, L_height] ],\n",
    "             'boundary_condition': inlet_con }\n",
    "\n",
    "list_of_dirichlet_boundaries = [bdry1, wall_left, wall_top, wall_bot, wall_right ]\n",
    "#list_of_dirichlet_boundaries = [bdry1, wall_left, wall_top, wall_bot ]\n",
    "list_of_periodic_boundaries =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncompressibleNN(torch.nn.Module):\n",
    "    \n",
    "    ### Incompressible neural network\n",
    "    ### curl operation built in\n",
    "    \n",
    "    def __init__(self, depth, width, x_dim, is_unsteady, **nn_param):\n",
    "        super(IncompressibleNN, self).__init__()\n",
    "        \n",
    "        self.x_dim = x_dim\n",
    "        self.input_dim = self.x_dim + is_unsteady\n",
    "        \n",
    "        self.dim_out = [1, 3][self.x_dim==3]\n",
    "        \n",
    "        modules = []\n",
    "        modules.append(torch.nn.Linear(self.input_dim, depth))\n",
    "        for i in range(width - 1):\n",
    "            modules.append(torch.nn.Linear(depth, depth))\n",
    "            modules.append(torch.nn.Tanh())\n",
    "        modules.append(torch.nn.Linear(depth, self.dim_out))\n",
    "                       \n",
    "        self.sequential_model = torch.nn.Sequential(*modules)\n",
    "    \n",
    "    def curl(self, a, x):\n",
    "        if self.x_dim == 2:\n",
    "            \n",
    "            dadx = torch.autograd.grad(a, x, grad_outputs = torch.ones_like(a), \n",
    "                                        create_graph = True, retain_graph = True)[0]\n",
    "\n",
    "            u = torch.stack([dadx[:,1], -dadx[:,0]] , dim=1)\n",
    "            \n",
    "        elif self.x_dim == 3:\n",
    "            e = torch.eye(self.x_dim, device=x.device)\n",
    "\n",
    "            da0dx = torch.autograd.grad(a, x, grad_outputs=e[0,:].repeat(a.size(0), 1), \n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "            da1dx = torch.autograd.grad(a, x, grad_outputs=e[1,:].repeat(a.size(0), 1),\n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "            da2dx = torch.autograd.grad(a, x, grad_outputs=e[2,:].repeat(a.size(0), 1),\n",
    "                                        create_graph=True, retain_graph = True)[0]\n",
    "\n",
    "            u = torch.stack([da2dx[:,1] - da1dx[:,2], da0dx[:,2] - da2dx[:,0], da1dx[:,0] - da0dx[:,1] ], dim=1)         \n",
    "        return u\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a = self.sequential_model(x)\n",
    "        u = self.curl(a, x)\n",
    "            \n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Domain\n",
    "class Domain:\n",
    "    ### This class defines the domain using the parameters provided\n",
    "    ### It sets up the boundingbox and each boundary\n",
    "\n",
    "    def __init__(self, is_unsteady, boundingbox, \n",
    "                list_of_dirichlet_boundaries,\n",
    "                list_of_periodic_boundaries=False):\n",
    "        \n",
    "        self.boundingbox = boundingbox\n",
    "        self.is_unsteady = is_unsteady\n",
    "\n",
    "        self.num_of_boundaries = len(list_of_dirichlet_boundaries)\n",
    "        \n",
    "        # Unpack dirichlet boundary descriptions\n",
    "        self.boundaries = []\n",
    "        for specs in list_of_dirichlet_boundaries:\n",
    "            ### 2D boundaries\n",
    "            if specs['type'] == 'line':\n",
    "                self.boundaries.append( bdry_line( point = specs['point'], \n",
    "                                                   normal = specs['normal'],\n",
    "                                                   endpoints = specs['endpoints'],\n",
    "                                                   boundary_condition = specs['boundary_condition'] ))\n",
    "            \n",
    "            if specs['type'] == 'disk':\n",
    "                self.boundaries.append( bdry_disk( centre = specs['centre'],\n",
    "                                                   radius = specs['radius'], \n",
    "                                                   boundary_condition = specs['boundary_condition'] ))\n",
    "          \n",
    "        # Unpack any periodic boundaries\n",
    "        self.periodic_boundaries = []\n",
    "        for specs in list_of_periodic_boundaries:\n",
    "            self.periodic_boundaries.append( bdry_periodic( variable = specs['variable'],\n",
    "                                                            base = specs['base'],\n",
    "                                                            top = specs['top']  ))\n",
    "\n",
    "### Boundary Classes\n",
    "\n",
    "# 2D Boundaries\n",
    "class bdry_disk:\n",
    "    ### Class structure for a 2D solid disk boundary, the domain being outside the disk\n",
    "    \n",
    "    def __init__(self, centre, radius, boundary_condition):\n",
    "        ### Centre and Radius\n",
    "        self.centre = torch.tensor( centre )\n",
    "        self.radius = radius\n",
    "\n",
    "        self.bdry_cond = boundary_condition\n",
    "        \n",
    "        self.angles = [0, 2*math.pi]\n",
    "            \n",
    "            \n",
    "    def make_bdry_pts(self, num_bdry, boundingbox, other_bdrys):\n",
    "        ### Make random points along the boundary\n",
    "        \n",
    "        #theta = 2*math.pi*torch.rand(num_bdry)\n",
    "        theta = torch.linspace(0,2*math.pi, 2**7)\n",
    "        \n",
    "        #rad_theta = torch.cartesian_prod(self.radius*torch.sqrt(torch.linspace(0,1, 2**4)),\n",
    "        #                                 torch.linspace(0,2*math.pi, 2**6))\n",
    "\n",
    "        Xbdry = torch.stack((self.radius*torch.cos(theta) + self.centre[0],\n",
    "                                 self.radius*torch.sin(theta) + self.centre[1]),dim=1 )\n",
    "\n",
    "        #Xbdry = torch.stack( (rad_theta[:,0]*torch.cos(rad_theta[:,1]) + self.centre[0],\n",
    "        #                      rad_theta[:,0]*torch.sin(rad_theta[:,1]) + self.centre[1]), dim=1)\n",
    "\n",
    "        \n",
    "        #Xbdry = torch.cat( ( Spacebdry, \n",
    "        #                     boundingbox[2][1]*torch.rand(num_bdry,1),\n",
    "        #                     boundingbox[3][1]*torch.rand(num_bdry,1),\n",
    "        #                     boundingbox[4][1]*torch.rand(num_bdry,1),), dim=1)\n",
    "\n",
    "    \n",
    "        ### Check if outside other bdrys\n",
    "        ### and remake bdry points\n",
    "        outside = torch.zeros(Xbdry.size(0), dtype=torch.bool)\n",
    "\n",
    "        for bdry in other_bdrys:\n",
    "            outside += bdry.dist_to_bdry(Xbdry) < 0\n",
    "        \n",
    "        if any(outside):\n",
    "            Xbdry[outside,:] = self.make_bdry_pts(torch.sum(outside), boundingbox, is_unsteady, other_bdrys)\n",
    "\n",
    "        return Xbdry\n",
    "            \n",
    "    def dist_to_bdry(self, X):\n",
    "        ### Signed distance to boundary\n",
    "        ### positive = inside domain\n",
    "        ### negative = outside domain\n",
    "\n",
    "        distance = ( torch.norm(X[:,:2] - self.centre.to(X.device),dim=1) - self.radius )\n",
    "        return distance\n",
    "    \n",
    "class bdry_line:\n",
    "    ### Class structure for a line boundary\n",
    "    ###       normal vector points inside\n",
    "    \n",
    "    def __init__(self, point, normal, endpoints, boundary_condition):\n",
    "        self.point = torch.tensor(  point )\n",
    "        self.normal = torch.tensor( normal )\n",
    "        self.constant = -sum( self.normal*self.point )\n",
    "        \n",
    "        self.bdry_cond = boundary_condition\n",
    "        \n",
    "        self.endpoints = torch.tensor(endpoints)\n",
    "        \n",
    "    def make_bdry_pts(self, num_bdry, boundingbox, other_bdrys):\n",
    "           \n",
    "        #Spacebdry = ( self.endpoints[1] - self.endpoints[0] )*torch.rand((num_bdry,1)) + self.endpoints[0]\n",
    "        Xbdry = ( self.endpoints[1] - self.endpoints[0] )*torch.linspace(0,1, num_bdry)[:,None] + self.endpoints[0]\n",
    "        \n",
    "        #Xbdry = torch.cat( ( Spacebdry, \n",
    "        #                       boundingbox[2][1]*torch.rand(num_bdry,1),\n",
    "        #                       boundingbox[3][1]*torch.rand(num_bdry,1),\n",
    "        #                       boundingbox[4][1]*torch.rand(num_bdry,1),), dim=1)\n",
    "        \n",
    "        ### Check if outside other bdrys\n",
    "        ### and remake bdry points\n",
    "        #outside = torch.zeros(Xbdry.size(0), dtype=torch.bool)\n",
    "\n",
    "        #for bdry in other_bdrys:\n",
    "        #    outside += bdry.dist_to_bdry(Xbdry[:,:2]) < 0\n",
    "        \n",
    "        #if any(outside):\n",
    "        #    Xbdry[outside,:] = self.make_bdry_pts(torch.sum(outside), boundingbox, is_unsteady, other_bdrys)\n",
    "\n",
    "        return Xbdry\n",
    "    \n",
    "    def dist_to_bdry(self, X):\n",
    "        ### Signed distance to boundary\n",
    "        ### positive = inside domain\n",
    "        ### negative = outside domain\n",
    "        distance = torch.sum( self.normal.to(X.device)*X[:,:2], dim=1) + self.constant\n",
    "        \n",
    "        return distance\n",
    "\n",
    "class Walker_Data(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, num_walkers, boundingbox, boundaries):\n",
    "        \n",
    "        Xold = generate_interior_points(num_walkers, boundingbox, boundaries)\n",
    "        #region = close_to_region(Xold)\n",
    "        \n",
    "        self.location = Xold\n",
    "        self.num_pts = num_walkers\n",
    "        #self.region = region\n",
    "        \n",
    "    def __len__(self):\n",
    "        ### How many data points are there?\n",
    "        return self.num_pts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ### Gets one sample of data\n",
    "        ### \n",
    "        return self.location[index,:], index\n",
    "        \n",
    "class Boundary_Data(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, num_bdry, boundingbox, boundaries):\n",
    "        \n",
    "        Xbdry, Ubdry = generate_boundary_points(num_bdry, boundingbox, boundaries)\n",
    "        \n",
    "        self.location = Xbdry\n",
    "        self.num_pts = Xbdry.size(0)\n",
    "        self.value = Ubdry\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_pts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.location[index,:], self.value[index,:]    \n",
    "\n",
    "class Initial_Data(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, num_init, boundingbox, boundaries):\n",
    "        \n",
    "        Xinit = generate_interior_points(num_init, boundingbox, boundaries)\n",
    "        Xinit[:,2] = 0\n",
    "\n",
    "        self.location = Xinit\n",
    "        self.num_pts = num_init\n",
    "        self.value = initial_con(Xinit)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_pts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.location[index,:], self.value[index,:]    \n",
    "\n",
    "def generate_interior_points(num_walkers, boundingbox, boundaries):\n",
    "    ### Generate points inside the domain\n",
    "\n",
    "    X = torch.empty( (num_walkers, len(boundingbox)) )\n",
    "\n",
    "    for ii in range(len(boundingbox)):\n",
    "        X[:,ii] = (boundingbox[ii][1] - boundingbox[ii][0])*torch.rand( (num_walkers) ) + boundingbox[ii][0]\n",
    "        \n",
    "        #Parameters are given in log scale, rescale back\n",
    "        #if ii > 2:\n",
    "        #    X[:,ii] = 10**X[:,ii]\n",
    "\n",
    "    outside = torch.zeros( X.size(0), dtype=torch.bool)\n",
    "    for bdry in boundaries:\n",
    "        outside += bdry.dist_to_bdry(X) < 0\n",
    "    \n",
    "    if any(outside):\n",
    "        X[outside,:] = generate_interior_points(torch.sum(outside), boundingbox, boundaries)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def generate_boundary_points(num_bdry, boundingbox, boundaries):\n",
    "    ### Generate points along the boundary\n",
    "    \n",
    "    points_per_bdry = []\n",
    "    utrue_per_bdry = []\n",
    "    \n",
    "    # Generate num_bdry points for each boundary\n",
    "    for ii in range(len(boundaries)):\n",
    "        bdry = boundaries[ii]\n",
    "        other_bdrys = boundaries[:ii] + boundaries[ii+1:]\n",
    "\n",
    "        # Generate boundary points\n",
    "        X_in_bdry =  bdry.make_bdry_pts(num_bdry, boundingbox, other_bdrys)\n",
    "        U_in_bdry = bdry.bdry_cond(X_in_bdry)\n",
    "\n",
    "        points_per_bdry.append( X_in_bdry )\n",
    "        utrue_per_bdry.append( U_in_bdry )\n",
    "\n",
    "    Xbdry = torch.cat( points_per_bdry, dim=0)\n",
    "    Ubdry_true = torch.cat( utrue_per_bdry, dim=0)\n",
    "\n",
    "    # Sample from above boundary points\n",
    "    #indices = torch.multinomial( torch.arange( len(boundaries)*num_bdry, dtype=torch.float ), num_bdry)\n",
    "    \n",
    "    #Xbdry = Xbdry[indices,:]\n",
    "    #Ubdry_true = Ubdry_true[indices,:]\n",
    "    \n",
    "    return Xbdry, Ubdry_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialization\n",
    "\n",
    "there_are_boundaries = bool(list_of_dirichlet_boundaries)\n",
    "\n",
    "nn_param = {'depth': nn_depth,\n",
    "            'width': nn_width,\n",
    "            'x_dim': x_dim,\n",
    "            'is_unsteady': is_unsteady,\n",
    "            'output_dim': output_dim,\n",
    "            }\n",
    "                \n",
    "################ Preparing the model #################\n",
    "\n",
    "#print(\"Initializing the model\")\n",
    "\n",
    "### Make boundaries defining the domain\n",
    "MyDomain = Domain(is_unsteady, boundingbox, \n",
    "                  list_of_dirichlet_boundaries,\n",
    "                  list_of_periodic_boundaries)\n",
    "\n",
    "### Initialize the Model\n",
    "#model = IncompressibleNN(**nn_param) #.to(dev)\n",
    "model = IncompressibleNN(**nn_param).to(dev)\n",
    "\n",
    "mseloss = torch.nn.MSELoss(reduction = 'mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                        lr=learning_rate, \n",
    "                        betas=adam_beta, \n",
    "                        weight_decay=weight_decay)\n",
    "\n",
    "### Create Walkers and Boundary points and Organize into DataLoader\n",
    "RWalkers = Walker_Data(num_walkers, boundingbox, MyDomain.boundaries)\n",
    "RWalkers_batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if update_walkers == 'move':\n",
    "    move_RWalkers = torch.zeros_like(RWalkers.location)\n",
    "\n",
    "if there_are_boundaries:\n",
    "    BPoints = Boundary_Data(num_bdry, boundingbox, MyDomain.boundaries)\n",
    "    BPoints_batch = torch.utils.data.DataLoader(BPoints, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if is_unsteady:\n",
    "    IPoints = Initial_Data(num_init, boundingbox, MyDomain.boundaries)\n",
    "    IPoints_batch = torch.utils.data.DataLoader(IPoints, batch_size=num_batch, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "def evaluate_NS(X, model, x_dim, boundaries, num_batch, num_ghost, tol):\n",
    "    \n",
    "    ### Evaluate model\n",
    "    Uold = model(X)\n",
    "    \n",
    "    ### Move walkers\n",
    "    # Increase dimension of the brownian motion\n",
    "    #Space_new = X[:,:2].repeat(num_ghost,1) - dt*Uold.detach().repeat(num_ghost,1) + np.sqrt(2*dt*mu)*torch.randn((num_batch*num_ghost, x_dim), device=X.device, requires_grad=True)\n",
    "    #Time_new = X[:,2,None].repeat(num_ghost,1) - dt\n",
    "    #Param_new = X[:,x_dim+1:].repeat(num_ghost,1)\n",
    "\n",
    "    #Xnew = torch.cat( (Space_new, Time_new, Param_new), dim=1 )\n",
    "    #Xnew = torch.cat( (Space_new, Time_new), dim=1 )\n",
    "\n",
    "    Xnew = X.repeat(num_ghost,1) - dt*Uold.detach().repeat(num_ghost,1) + np.sqrt(2*dt*mu)*torch.randn((num_batch*num_ghost, x_dim), device=X.device, requires_grad=True)\n",
    "\n",
    "    Unew = model(Xnew)\n",
    "\n",
    "    ### Calculate exits and re-evaluate points\n",
    "    Xnew, Unew, outside = exit_condition(X.repeat(num_ghost,1), Xnew, Unew, boundaries, tol)\n",
    "\n",
    "    return Xnew, Uold, Unew, outside[:num_batch]\n",
    "\n",
    "def exit_condition(Xold, Xnew, Unew, boundaries, tol):\n",
    "    ### Calculate exit conditions\n",
    "    outside = torch.zeros( Xnew.size(0), dtype=torch.bool, device=Xnew.device)\n",
    "    \n",
    "    for bdry in boundaries:\n",
    "        outside_bdry = bdry.dist_to_bdry(Xnew) < 0\n",
    "        if torch.sum(outside_bdry) > 0:\n",
    "            ### Bisection to get close to exit location up to tolerance tol\n",
    "            \n",
    "            Xnew[outside_bdry,:] = find_bdry_exit(Xold[outside_bdry,:], Xnew[outside_bdry,:], bdry, tol)\n",
    "            Unew[outside_bdry,:] = bdry.bdry_cond(Xnew[outside_bdry,:])\n",
    "            \n",
    "        outside += outside_bdry\n",
    "\n",
    "    ### Check for time = 0\n",
    "    ### Note: This prioritizes time exit over bdry exit\n",
    "    ### Question: \n",
    "    ###     Should we take a point at the initial time (by projecting or something)\n",
    "    ###     or is within tol good enough?\n",
    "    #hit_initial = Xnew[:,2] < 0\n",
    "    #Xnew[hit_initial,:] = find_time_exit(Xold[hit_initial,:], Xnew[hit_initial,:], tol)\n",
    "    #Unew[hit_initial,:] = initial_con(Xnew[hit_initial,:])\n",
    "\n",
    "    #outside += hit_initial\n",
    "\n",
    "    return Xnew, Unew, outside\n",
    "\n",
    "def find_bdry_exit(Xold, Xnew, bdry, tol):\n",
    "    ### Bisection algorithm to find the exit between Xnew and Xold up to a tolerance \n",
    "    \n",
    "    Xmid = (Xnew + Xold)/2\n",
    "    \n",
    "    dist = bdry.dist_to_bdry(Xmid)\n",
    "    \n",
    "    # above tolerance = inside\n",
    "    # below tolerance = outside\n",
    "    above_tol = dist > tol\n",
    "    below_tol = dist < -tol\n",
    "    \n",
    "    if torch.sum(above_tol + below_tol) > 0:\n",
    "        Xnew[below_tol,:] = Xmid[below_tol,:]\n",
    "        Xold[above_tol,:] = Xmid[above_tol,:]\n",
    "        \n",
    "        Xmid[above_tol + below_tol,:] = find_bdry_exit(Xold[above_tol + below_tol,:], Xnew[above_tol + below_tol,:], bdry, tol)\n",
    "\n",
    "    return Xmid\n",
    "\n",
    "def find_time_exit(Xold, Xnew, tol):\n",
    "    ### Bisection algorithm to find the time exit up to a tolerance\n",
    "    \n",
    "    Xmid = (Xnew + Xold)/2\n",
    "\n",
    "    # above tolerance = inside\n",
    "    # below tolerance = outside\n",
    "    above_tol = Xmid[:,2] > tol\n",
    "    below_tol = Xmid[:,2] < -tol\n",
    "\n",
    "    if torch.sum(above_tol + below_tol) > 0:\n",
    "        Xnew[below_tol,:] = Xmid[below_tol,:]\n",
    "        Xold[above_tol,:] = Xmid[above_tol,:]\n",
    "        \n",
    "        Xmid[above_tol + below_tol,:] = find_time_exit(Xold[above_tol + below_tol,:], Xnew[above_tol + below_tol,:], tol)\n",
    "\n",
    "    return Xmid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors in first epoch\n",
      "Approx time: 25 minutes\n",
      "step = 500/1000, 0.215 s/step, time-to-go: 2 min\n",
      "step = 1000/1000, 0.220 s/step, time-to-go: 0 min\n"
     ]
    }
   ],
   "source": [
    "################ Training the model #################\n",
    "\n",
    "#print(\"Training has begun\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "### Run the training loop\n",
    "\n",
    "for step in range(num_step):\n",
    "\n",
    "    # Random Walkers - do in batches\n",
    "    for Xold, index in RWalkers_batch:\n",
    "\n",
    "        # Send to GPU and set requires grad flag\n",
    "        Xold = Xold.to(dev).requires_grad_(True)\n",
    "        #Xold = Xold.requires_grad_(True)\n",
    "\n",
    "        # Evaluate at old location and Move walkers\n",
    "        Xnew, Uold, Unew, outside = evaluate_NS(Xold, model, x_dim, MyDomain.boundaries, num_batch, num_ghost, tol)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = lambda_bell*mseloss(Uold, Unew.reshape(num_ghost, num_batch, output_dim).mean(0).detach())\n",
    "        loss.backward()\n",
    "\n",
    "        # No importance sampling. Walkers just move\n",
    "        # If moving walkers save the first ghost walker\n",
    "        if update_walkers == 'move':\n",
    "            if any(outside):\n",
    "                Xnew[:num_batch,:][outside,:] = generate_interior_points(torch.sum(outside),boundingbox,MyDomain.boundaries).to(dev)\n",
    "            move_RWalkers[index,:] = Xnew[:num_batch].detach().cpu()\n",
    "\n",
    "\n",
    "    # Boundary Points - do in batches\n",
    "    for Xbdry, Ubtrue in BPoints_batch:\n",
    "        Xbdry = Xbdry.to(dev).requires_grad_(True)\n",
    "        #Xbdry = Xbdry.requires_grad_(True)\n",
    "        Ubtrue = Ubtrue.to(dev).detach()\n",
    "        #Ubtrue = Ubtrue.detach()\n",
    "        Ubdry = model(Xbdry)\n",
    "        loss = lambda_bdry*mseloss(Ubdry, Ubtrue)\n",
    "        loss.backward()\n",
    "\n",
    "    # Initial Condition Points - do in batches\n",
    "    #if is_unsteady:\n",
    "    #    for Xinit, Uinittrue in IPoints_batch:\n",
    "    #        Xinit = Xinit.to(dev).requires_grad_(True)\n",
    "    #        #Xinit = Xinit.requires_grad_(True)\n",
    "    #        Uinittrue = Uinittrue.to(dev).detach()\n",
    "    #        #Ubtrue = Uinittrue.detach()\n",
    "    #        Uinit = model(Xinit)\n",
    "    #        loss = lambda_init*mseloss(Uinit, Uinittrue)\n",
    "    #        loss.backward()\n",
    "\n",
    "    # Make optimization step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Update walkers\n",
    "\n",
    "    if (step+1) % update_walkers_every == 0:\n",
    "        if update_walkers == 'move':\n",
    "            RWalkers.location = move_RWalkers\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "        #BPoints.location, BPoints.value = generate_boundary_points(num_bdry, boundingbox, MyDomain.boundaries)\n",
    "        #BPoints_batch = torch.utils.data.DataLoader(BPoints, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "        #IPoints.location = generate_interior_points(num_init, boundingbox, MyDomain.boundaries)\n",
    "        #IPoints.location[:,2] = 0\n",
    "        #IPoints.value = initial_con(IPoints.location)\n",
    "        #IPoints_batch = torch.utils.data.DataLoader(IPoints, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "    # Print statements\n",
    "    if step == 0:\n",
    "        print('No errors in first epoch')\n",
    "        current_time = time.time()\n",
    "        print('Approx time: {:.0f} minutes'.format((current_time - start_time)*num_step/60))\n",
    "    if (step+1) % update_print_every == 0:\n",
    "        current_time = time.time()\n",
    "        print('step = {0}/{1}, {2:2.3f} s/step, time-to-go:{3:2.0f} min'.format(\n",
    "                step+1, num_step, (current_time - start_time) / (step + 1), \n",
    "            (current_time - start_time) / (step + 1) * (num_step - step - 1)/60))\n",
    "\n",
    "# Save model as pickle file\n",
    "\n",
    "torch.save(model.state_dict(), \"savedmodels/\" + savemodel + \".pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x28677c404c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(BPoints.location[:,0].cpu().numpy(),BPoints.location[:,1].cpu().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06d3ad103a38a5e5980b0a2ddf222334b9b3630c94a7e75a8e45e8afe280f469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
