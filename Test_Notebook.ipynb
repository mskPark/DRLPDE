{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model = DRLPDE_main.maintraining(param='JCPexample5', use_cuda=True)\n",
    "### calculate error\n",
    "### Repeat, make a error distribution plot\n",
    "\n",
    "### Do for different parameters\n",
    "### eg. number of training steps\n",
    "###     Size of network?\n",
    "###     learning rate?\n",
    "###     Number of Walkers\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import DRLPDE_nn\n",
    "import DRLPDE_functions.DefineDomain\n",
    "import DRLPDE_functions.EvaluateWalkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Organize parameters related to deep learning solver\n",
    "############## Walker and Boundary Parameters ############\n",
    "\n",
    "number_of_runs = 10\n",
    "\n",
    "problem = 'JCPexample1'\n",
    "\n",
    "trials = np.zeros((number_of_runs, 2, 5))\n",
    "\n",
    "# Time step\n",
    "dt = 1e-4\n",
    "\n",
    "# exit tolerance\n",
    "tol = 1e-6\n",
    "\n",
    "# Number of walkers\n",
    "num_walkers = 2**13\n",
    "num_ghost = 256\n",
    "num_batch = 2**11\n",
    "\n",
    "# Update walkers\n",
    "# Options: \n",
    "#    move -- moves walkers to one of their new locations\n",
    "#    remake -- remake walkers at each training step\n",
    "#    fixed -- keeps walkers fixed\n",
    "update_walkers = 'move'\n",
    "update_walkers_every = 1\n",
    "\n",
    "# Number of boundary points \n",
    "num_bdry = 2**10\n",
    "num_batch_bdry = 2**8\n",
    "\n",
    "# Number of initial points\n",
    "num_init = 2**10\n",
    "num_batch_init = 2**8\n",
    "\n",
    "############## Training Parameters #######################\n",
    "\n",
    "# Training epochs\n",
    "num_epoch = 1000\n",
    "update_print_every = 1000\n",
    "\n",
    "# Neural Network Architecture\n",
    "nn_depth = 20\n",
    "nn_width = 4\n",
    "\n",
    "# Weighting of losses\n",
    "lambda_bell = 1e-2/dt\n",
    "lambda_bdry = 1\n",
    "lambda_init = 0\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-2\n",
    "adam_beta = (0.9,0.999)\n",
    "weight_decay = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "    \n",
    "DRLPDE_param = importlib.import_module(\".\" + problem, package='examples')\n",
    "    \n",
    "### Use cuda\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "boundingbox = DRLPDE_param.boundingbox\n",
    "list_of_dirichlet_boundaries = DRLPDE_param.list_of_dirichlet_boundaries\n",
    "list_of_periodic_boundaries = DRLPDE_param.list_of_periodic_boundaries\n",
    "pde_type = DRLPDE_param.pde_type\n",
    "is_unsteady = DRLPDE_param.is_unsteady\n",
    "output_dim = DRLPDE_param.output_dim\n",
    "\n",
    "nn_param = {'depth': nn_depth,\n",
    "            'width': nn_width,\n",
    "            'x_dim':DRLPDE_param.x_dim,\n",
    "            'is_unsteady':DRLPDE_param.is_unsteady ,\n",
    "            'output_dim':DRLPDE_param.output_dim\n",
    "            }\n",
    "\n",
    "move_walkers_param={'x_dim': DRLPDE_param.x_dim,\n",
    "                    'mu': DRLPDE_param.mu,\n",
    "                    'dt': dt,\n",
    "                    'num_batch': num_batch,\n",
    "                    'num_ghost': num_ghost,\n",
    "                    'tol': tol\n",
    "                    }\n",
    "\n",
    "eval_model_param={'dt': dt,\n",
    "                    'forcing': DRLPDE_param.forcing}\n",
    "\n",
    "### Import functions\n",
    "if is_unsteady:\n",
    "    # Include time range in bounding box\n",
    "    boundingbox.append(DRLPDE_param.time_range)\n",
    "    init_con = DRLPDE_param.init_con\n",
    "    \n",
    "    if pde_type == 'NavierStokes':\n",
    "        move_Walkers = DRLPDE_functions.EvaluateWalkers.move_Walkers_NS_unsteady\n",
    "    elif pde_type == 'Parabolic':\n",
    "        move_Walkers = DRLPDE_functions.EvaluateWalkers.move_Walkers_Parabolic\n",
    "    elif pde_type == 'StokesFlow':\n",
    "        move_Walkers = DRLPDE_functions.EvaluateWalkers.move_Walkers_Stokes_unsteady\n",
    "else:\n",
    "    if pde_type == 'NavierStokes':\n",
    "        move_Walkers = DRLPDE_functions.EvaluateWalkers.move_Walkers_NS_steady\n",
    "    elif pde_type == 'Elliptic':\n",
    "        move_Walkers = DRLPDE_functions.EvaluateWalkers.move_Walkers_Elliptic\n",
    "    elif pde_type == 'StokesFlow':\n",
    "        move_Walkers = DRLPDE_functions.EvaluateWalkers.move_Walkers_Stokes_steady\n",
    "\n",
    "if pde_type == 'NavierStokes' or 'StokesFlow':\n",
    "    evaluate_model = DRLPDE_functions.EvaluateWalkers.evaluate_model_NS\n",
    "else:\n",
    "    evaluate_model = DRLPDE_functions.EvaluateWalkers.evaluate_model_PDE\n",
    "    \n",
    "    move_walkers_param[\"drift\"] = DRLPDE_param.drift\n",
    "    eval_model_param[\"reaction\"] = DRLPDE_param.reaction\n",
    "\n",
    "\n",
    "################ Preparing the model #################\n",
    "\n",
    "#print(\"Initializing the model\")\n",
    "\n",
    "### Make boundaries defining the domain\n",
    "Domain = DRLPDE_functions.DefineDomain.Domain(is_unsteady, boundingbox, \n",
    "                                                list_of_dirichlet_boundaries,\n",
    "                                                list_of_periodic_boundaries)\n",
    "\n",
    "### Initialize the Model\n",
    "if pde_type == 'NavierStokes' or 'StokesFlow':\n",
    "    MyNeuralNetwork = DRLPDE_nn.IncompressibleNN\n",
    "else:\n",
    "    MyNeuralNetwork = DRLPDE_nn.FeedForwardNN\n",
    "\n",
    "if DRLPDE_param.loadmodel:\n",
    "    model = torch.load(\"savedmodels/\" + DRLPDE_param.loadmodel + \".pt\")\n",
    "    print(\"Using model from savedmodels/\" + DRLPDE_param.loadmodel + \".pt\")\n",
    "else:\n",
    "    model = MyNeuralNetwork(**nn_param).to(dev)\n",
    "\n",
    "mseloss = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                        lr=DRLPDE_param_solver.learning_rate, \n",
    "                        betas=DRLPDE_param_solver.adam_beta, \n",
    "                        weight_decay=DRLPDE_param_solver.weight_decay)\n",
    "\n",
    "### Create Walkers and Boundary points and Organize into DataLoader\n",
    "RWalkers = DRLPDE_functions.DefineDomain.Walker_Data(num_walkers, boundingbox, Domain.boundaries)\n",
    "RWalkers_batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if update_walkers == 'move':\n",
    "    move_RWalkers = torch.zeros_like(RWalkers.location)\n",
    "\n",
    "BPoints = DRLPDE_functions.DefineDomain.Boundary_Data(num_bdry, boundingbox, Domain.boundaries, is_unsteady)\n",
    "BPoints_batch = torch.utils.data.DataLoader(BPoints, batch_size=num_batch_bdry, shuffle=True)\n",
    "\n",
    "if is_unsteady:\n",
    "    InitPoints = DRLPDE_functions.DefineDomain.Initial_Data(num_init, boundingbox, Domain.boundaries, init_con)\n",
    "    InitPoints_batch = torch.utils.data.DataLoader(InitPoints, batch_size=num_batch_init, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "### Analytic Solution\n",
    "\n",
    "numpts_r = 10\n",
    "numpts_th =  60\n",
    "\n",
    "mu = 1\n",
    "L = 1  # Length of box the circle/sphere sits inside + Radius of Disk/Sphere\n",
    "v0 = 1\n",
    "\n",
    "### Analytic Solution\n",
    "r,th = torch.meshgrid([torch.linspace(0,1, numpts_r), \n",
    "                       torch.linspace(0,2*math.pi, numpts_th)])\n",
    "\n",
    "x1g = r*torch.cos(th)\n",
    "x2g = r*torch.sin(th)\n",
    "\n",
    "xg = torch.stack([x1g.reshape(-1), x2g.reshape(-1)], dim=-1).requires_grad_(True)\n",
    "\n",
    "integral_factor = 2*math.pi*r.detach().cpu().numpy()/(numpts_r-1)/(numpts_th-1)\n",
    "\n",
    "u1_true = - v0*r*torch.sin(th)\n",
    "u2_true = v0*r*torch.cos(th)\n",
    "\n",
    "u_true = torch.stack([u1_true, u2_true], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(num_epoch):\n",
    "\n",
    "    # Random Walkers - do in batches\n",
    "    for Xold, index in RWalkers_batch:\n",
    "\n",
    "        # Send to GPU and set requires grad flag\n",
    "        Xold = Xold.to(dev).requires_grad_(True)\n",
    "\n",
    "        # Evaluate at old location and Move walkers\n",
    "        Xnew, Uold, outside = move_Walkers(Xold, model, Domain, **move_walkers_param)\n",
    "\n",
    "        # Evaluate at new location and average\n",
    "        Unew = evaluate_model(Xold, Xnew, model, **eval_model_param).reshape(num_ghost, \n",
    "                                                                                num_batch,\n",
    "                                                                                output_dim).mean(0)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = lambda_bell*mseloss(Uold, Unew.detach())\n",
    "        loss.backward()\n",
    "\n",
    "        # If moving walkers save the first ghost walker\n",
    "        if update_walkers == 'move':\n",
    "            if any(outside):\n",
    "                Xnew[:num_batch,:][outside,:] = DRLPDE_functions.DefineDomain.generate_interior_points(torch.sum(outside), \n",
    "                                                                                            boundingbox,\n",
    "                                                                                            Domain.boundaries).to(dev)\n",
    "            move_RWalkers[index,:] = Xnew[:num_batch].detach().cpu()\n",
    "\n",
    "\n",
    "    # Boundary Points - do in batches\n",
    "    for Xbdry, Ubtrue in BPoints_batch:\n",
    "        Xbdry = Xbdry.to(dev).requires_grad_(True)\n",
    "        Ubtrue = Ubtrue.to(dev).detach()\n",
    "        Ubdry = model(Xbdry)\n",
    "        loss = lambda_bdry*mseloss(Ubdry, Ubtrue)\n",
    "        loss.backward()\n",
    "\n",
    "    # Initial Points - do in batches\n",
    "    if is_unsteady:\n",
    "        for Xinit, Uinit_true in InitPoints_batch:\n",
    "            Xinit = Xinit.to(dev).requires_grad_(True)\n",
    "            Uinit_true = Uinit_true.to(dev).detach()\n",
    "            Uinit = model(Xinit)\n",
    "            loss = lambda_bdry*mseloss(Uinit, Uinit_true)\n",
    "            loss.backward()\n",
    "\n",
    "    # Make optimization step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Update walkers\n",
    "\n",
    "    if (step+1) % update_walkers_every == 0:\n",
    "        if update_walkers == 'move':\n",
    "            RWalkers.location = move_RWalkers\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "        elif update_walkers == 'remake':\n",
    "            RWalkers = DRLPDE_functions.DefineDomain.Walker_Data(num_walkers, boundingbox, Domain.boundaries)\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.172 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.171 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.165 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.171 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.170 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.166 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.165 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.172 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.172 s/step, time-to-go: 0s\n",
      "No errors in first epoch: Training will continue\n",
      "step = 10/10, 0.168 s/step, time-to-go: 0s\n"
     ]
    }
   ],
   "source": [
    "error_distribution = np.zeros((number_of_runs, 2))\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    \n",
    "    \n",
    "\n",
    "    ug = model(xg)\n",
    "    ug = ug.reshape([numpts_r, numpts_th, 2])\n",
    "\n",
    "    u1_approx = ug.select(-1, 0).detach().cpu().numpy()\n",
    "    u2_approx = ug.select(-1, 1).detach().cpu().numpy()\n",
    "\n",
    "    x1plot = x1g.detach().cpu().numpy()\n",
    "    x2plot = x2g.detach().cpu().numpy()\n",
    "\n",
    "    u1_plot = u1_true.detach().cpu().numpy()\n",
    "    u2_plot = u2_true.detach().cpu().numpy()\n",
    "\n",
    "    L2_error = np.sqrt( np.sum( ((u1_approx - u1_plot)**2)*integral_factor) \\\n",
    "                    + np.sum( ((u2_approx - u2_plot)**2 )*integral_factor) )\n",
    "    Linf_error = np.max( [np.max( np.abs(u1_approx - u1_plot)) , np.max( np.abs(u2_approx - u2_plot))])\n",
    "\n",
    "    error_distribution[run,0] = L2_error\n",
    "    error_distribution[run,1] = Linf_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save errors\n",
    "\n",
    "trials[:,0,1] = error_distribution[:,0]\n",
    "trials[:,1,1] = error_distribution[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
