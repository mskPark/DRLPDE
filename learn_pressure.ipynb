{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to learn pressure term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Learn pressure term through its gradient:\n",
    "###     Setup neural network, train through gradient\n",
    "###     - Function that evaluates gradient\n",
    "###     - Training data: Average of (Unew + Uforcing term)/dt\n",
    "###     - To lock down the constant: Need condition\n",
    "###         - Sum of pressure = 0\n",
    "###         - Pressure at a point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import DRLPDE_functions.EvaluateWalkers\n",
    " \n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global L_height, v0\n",
    "\n",
    "############## Save model and/or Load model ##############\n",
    "\n",
    "# Physical Dimension\n",
    "x_dim = 2\n",
    "output_dim = 2\n",
    "\n",
    "is_unsteady = False\n",
    "input_dim = x_dim + is_unsteady\n",
    "\n",
    "L_height = 0.5\n",
    "v0 = 1.513787\n",
    "\n",
    "# Is there a true solution\n",
    "exists_analytic_sol = False\n",
    "# If there is a true solution, provide contour levels\n",
    "plot_levels = np.linspace(-1,1,100)\n",
    "\n",
    "def true_solution(X):\n",
    "    pass\n",
    "\n",
    "################# PDE Coefficients ########################\n",
    "\n",
    "# PDE type:\n",
    "pde_type = 'NavierStokes'\n",
    "\n",
    "# Diffusion coefficient\n",
    "mu = 1\n",
    "\n",
    "# Forcing term\n",
    "def forcing(X):\n",
    "    f = torch.zeros( (X.size(0), output_dim), device=X.device)\n",
    "    return f\n",
    "\n",
    "################# Boundary and Initial Conditions ###########\n",
    "# Use pytorch expressions to make boundary and initial conditions \n",
    "#\n",
    "# To make different boundary conditions for each boundary\n",
    "#     ensure the correct bdry_con is called when defining the boundaries\n",
    "\n",
    "def bdry_con(X):\n",
    "    u = torch.zeros( (X.size(0), output_dim), device=X.device)\n",
    "    return u\n",
    "\n",
    "def inlet_con(X):\n",
    "    u = torch.zeros_like(X, device=X.device)\n",
    "    \n",
    "    u[:,0] = v0*torch.mul((L_height - X[:,1]),(L_height + X[:,1]))/(L_height**2)\n",
    "\n",
    "    return u\n",
    "\n",
    "#################  Make the domain  #######################\n",
    "#     First define a bounding box containing your domain\n",
    "#         Syntax: [ x interval, y interval, z interval ]\n",
    "#         Points will be sampled through rejection sampling\n",
    "#\n",
    "#     Define each boundary\n",
    "#         lines: [ 'line', point, normal, endpoints, bdry_condition ]\n",
    "#         disk:  [ 'disk', centre, radius, endpoints, bdry_condition]\n",
    "#         \n",
    "#     Intersections of boundaries must be input manually\n",
    "#         These should be ordered as points will be sampled from first to second\n",
    "#         only 2 intersection points allowed\n",
    "#         \n",
    "#     Boundary condition is given by a function using pytorch expressions\n",
    "\n",
    "\n",
    "boundingbox = [ [0, 5*L_height], [-L_height,L_height] ]\n",
    "\n",
    "wall_left = {'type':'line',\n",
    "             'point': [0, -L_height],\n",
    "             'normal': [1,0],\n",
    "             'endpoints': [ [0, -L_height], [0, L_height] ],\n",
    "             'boundary_condition': inlet_con }\n",
    "\n",
    "wall_top = { 'type':'line',\n",
    "             'point': [0, L_height],\n",
    "             'normal':  [0,-1],\n",
    "             'endpoints': [ [0, L_height], [5*L_height, L_height] ],\n",
    "             'boundary_condition': bdry_con }\n",
    "\n",
    "wall_bot = {'type':'line',\n",
    "             'point': [0,-L_height],\n",
    "             'normal': [0, 1],\n",
    "             'endpoints': [ [0, -L_height], [5*L_height, -L_height] ],\n",
    "             'boundary_condition': bdry_con }\n",
    "\n",
    "list_of_dirichlet_boundaries = [wall_left, wall_top, wall_bot ]\n",
    "list_of_periodic_boundaries =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time step\n",
    "dt = 1e-2\n",
    "# exit tolerance\n",
    "tol = 1e-6\n",
    "\n",
    "# Number of walkers\n",
    "\n",
    "numpts = 2**12\n",
    "\n",
    "#numpts_x = 2**8\n",
    "#numpts_y = 2**4\n",
    "\n",
    "num_ghost = 512\n",
    "num_batch = 2**8\n",
    "\n",
    "# Update walkers\n",
    "# Options: \n",
    "#    move -- moves walkers to one of their new locations\n",
    "#    remake -- remake walkers at each training step\n",
    "#    fixed -- keeps walkers fixed\n",
    "update_walkers = 'fixed'\n",
    "update_walkers_every = 1\n",
    "############## Training Parameters #######################\n",
    "\n",
    "# Training epochs\n",
    "num_epoch = 5000\n",
    "\n",
    "update_print_every = 1000\n",
    "\n",
    "# Neural Network Architecture\n",
    "nn_depth = 20\n",
    "nn_width = 4\n",
    "\n",
    "# Weighting of losses\n",
    "lambda_bell = 1e2\n",
    "lambda_fix = 1e0\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-2\n",
    "adam_beta = (0.9,0.999)\n",
    "weight_decay = 0\n",
    "\n",
    "# Fixed pressure\n",
    "fixed_pressure  = 80\n",
    "fix_pressure_at = [dt,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    \n",
    "    ### Feed forward neural network\n",
    "    \n",
    "    def __init__(self, depth, width, x_dim, is_unsteady, output_dim, **nn_param):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        \n",
    "        self.input_dim = x_dim + is_unsteady\n",
    "        \n",
    "        modules = []\n",
    "        modules.append(nn.Linear(self.input_dim, depth))\n",
    "        for i in range(width - 1):\n",
    "            modules.append(nn.Linear(depth, depth))\n",
    "            modules.append(nn.ELU())\n",
    "        modules.append(nn.Linear(depth, output_dim))\n",
    "        \n",
    "        self.sequential_model = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = self.sequential_model(x)\n",
    "        \n",
    "        return a\n",
    "\n",
    "class PotentialNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, depth, width, x_dim, is_unsteady, output_dim, **nn_param):\n",
    "        super(PotentialNN, self).__init__()\n",
    "        \n",
    "        self.input_dim = x_dim + is_unsteady\n",
    "        \n",
    "        modules = []\n",
    "        modules.append(nn.Linear(self.input_dim, depth))\n",
    "        for i in range(width - 1):\n",
    "            modules.append(nn.Linear(depth, depth))\n",
    "            modules.append(nn.Tanh())\n",
    "        modules.append(nn.Linear(depth, 1))\n",
    "        \n",
    "        self.sequential_model = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        p = self.sequential_model(x)\n",
    "        \n",
    "        a = torch.autograd.grad(p, x, grad_outputs = torch.ones_like(p), create_graph = True, \n",
    "                                        retain_graph = True, only_inputs = True)[0]\n",
    "\n",
    "        return a\n",
    "\n",
    "    def evaluate_potential(self,x):\n",
    "        p = self.sequential_model(x)\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain:\n",
    "    ### This class defines the domain using the parameters provided\n",
    "    ### It sets up the boundingbox and each boundary\n",
    "\n",
    "    def __init__(self, is_unsteady, boundingbox, \n",
    "                list_of_dirichlet_boundaries,\n",
    "                list_of_periodic_boundaries):\n",
    "        \n",
    "        self.boundingbox = boundingbox\n",
    "        self.is_unsteady = is_unsteady\n",
    "\n",
    "        self.num_of_boundaries = len(list_of_dirichlet_boundaries)\n",
    "        \n",
    "        # Unpack dirichlet boundary descriptions\n",
    "        self.boundaries = []\n",
    "        for specs in list_of_dirichlet_boundaries:\n",
    "            ### 2D boundaries\n",
    "            if specs['type'] == 'line':\n",
    "                self.boundaries.append( bdry_line( point = specs['point'], \n",
    "                                                   normal = specs['normal'],\n",
    "                                                   endpoints = specs['endpoints'],\n",
    "                                                   boundary_condition = specs['boundary_condition'] ))\n",
    "        # Unpack any periodic boundaries\n",
    "        self.periodic_boundaries = []\n",
    "        for specs in list_of_periodic_boundaries:\n",
    "            self.periodic_boundaries.append( bdry_periodic( variable = specs['variable'],\n",
    "                                                            base = specs['base'],\n",
    "                                                            top = specs['top']  ))\n",
    "class bdry_line:\n",
    "    ### Class structure for a line boundary\n",
    "    ###       normal vector points inside\n",
    "    \n",
    "    def __init__(self, point, normal, endpoints, boundary_condition):\n",
    "        self.point = torch.tensor(  point )\n",
    "        self.normal = torch.tensor( normal )\n",
    "        self.constant = -sum( self.normal*self.point )\n",
    "        \n",
    "        self.bdry_cond = boundary_condition\n",
    "        \n",
    "        self.endpoints = torch.tensor(endpoints)\n",
    "        \n",
    "    def make_bdry_pts(self, num_bdry, boundingbox, is_unsteady, other_bdrys):\n",
    "        \n",
    "        if is_unsteady:\n",
    "            Xbdry = torch.cat( ( (self.endpoints[1] - self.endpoints[0] )*torch.rand((num_bdry,1)) + self.endpoints[0],\n",
    "                                 (boundingbox[-1][1] - boundingbox[-1][0])*torch.rand((num_bdry,1)) + boundingbox[-1][0]), dim=1)\n",
    "        else:    \n",
    "            Xbdry = ( self.endpoints[1] - self.endpoints[0] )*torch.rand((num_bdry,1)) + self.endpoints[0]\n",
    " \n",
    "        ### Check if outside other bdrys\n",
    "        ### and remake bdry points\n",
    "        outside = torch.zeros(Xbdry.size(0), dtype=torch.bool)\n",
    "\n",
    "        for bdry in other_bdrys:\n",
    "            outside += bdry.dist_to_bdry(Xbdry) < 0\n",
    "        \n",
    "        if any(outside):\n",
    "            Xbdry[outside,:] = self.make_bdry_pts(torch.sum(outside), boundingbox, is_unsteady, other_bdrys)\n",
    "\n",
    "        return Xbdry\n",
    "    \n",
    "    def dist_to_bdry(self, X):\n",
    "        ### Signed distance to boundary\n",
    "        ### positive = inside domain\n",
    "        ### negative = outside domain\n",
    "        distance = torch.sum( self.normal.to(X.device)*X[:,:2], dim=1) + self.constant\n",
    "        \n",
    "        return distance\n",
    "    \n",
    "    def plot_bdry(self, num_bdry):\n",
    "        Xplot = ( self.endpoints[1] - self.endpoints[0] )*torch.linspace(0, 1, num_bdry)[:,None] + self.endpoints[0]\n",
    "        \n",
    "        return Xplot\n",
    "\n",
    "def generate_interior_points( boundingbox, boundaries):\n",
    "    ### Generate points inside the domain\n",
    "    \n",
    "    ### Uniform Grid\n",
    "    #x1 = (boundingbox[0][1] - boundingbox[0][0])*torch.linspace( dt, 1-dt, numpts_x ) + boundingbox[0][0]\n",
    "    #x2 = (boundingbox[1][1] - boundingbox[1][0])*torch.linspace( dt, 1-dt, numpts_y ) + boundingbox[1][0]\n",
    "    #X = torch.cartesian_prod( x1, x2)\n",
    "\n",
    "    ### Randomly\n",
    "    x1 = (boundingbox[0][1] - boundingbox[0][0])*torch.rand(numpts) + boundingbox[0][0]\n",
    "    x2 = (boundingbox[1][1] - boundingbox[1][0])*torch.rand(numpts) + boundingbox[1][0]\n",
    "    X = torch.stack([x1, x2], dim=1)\n",
    "\n",
    "    outside = torch.zeros( X.size(0), dtype=torch.bool)\n",
    "    for bdry in boundaries:\n",
    "        outside += bdry.dist_to_bdry(X) < 0\n",
    "    \n",
    "    if any(outside):\n",
    "        X[outside,:] = generate_interior_points(torch.sum(outside), boundingbox, boundaries)\n",
    "        \n",
    "    return X\n",
    "\n",
    "class Walker_Data(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, boundingbox, boundaries):\n",
    "        \n",
    "        ### Define bdry exit condition\n",
    "        def find_bdry_exit(Xold, Xnew, bdry, tol):\n",
    "            ### Bisection algorithm to find the exit between Xnew and Xold up to a tolerance \n",
    "            \n",
    "            Xmid = (Xnew + Xold)/2\n",
    "            \n",
    "            dist = bdry.dist_to_bdry(Xmid)\n",
    "            \n",
    "            # above tolerance = inside\n",
    "            # below tolerance = outside\n",
    "            above_tol = dist > tol\n",
    "            below_tol = dist < -tol\n",
    "            \n",
    "            if torch.sum(above_tol + below_tol) > 0:\n",
    "                Xnew[below_tol,:] = Xmid[below_tol,:]\n",
    "                Xold[above_tol,:] = Xmid[above_tol,:]\n",
    "                \n",
    "                Xmid[above_tol + below_tol,:] = find_bdry_exit(Xold[above_tol + below_tol,:], Xnew[above_tol + below_tol,:], bdry, tol)\n",
    "\n",
    "            return Xmid\n",
    "\n",
    "        ### Generate points -- requires grad\n",
    "        self.Xold = generate_interior_points(boundingbox, boundaries).requires_grad_(True)\n",
    "\n",
    "        ### Move Walkers\n",
    "        Uold = model_velocity(self.Xold)\n",
    "        self.Xold.requires_grad_(False)\n",
    "\n",
    "        Zt = np.sqrt(dt)*torch.randn((numpts*num_ghost, x_dim))\n",
    "\n",
    "        self.Xnew = self.Xold.detach().repeat(num_ghost,1) - dt*Uold.detach().repeat(num_ghost,1) + np.sqrt(2*mu)*Zt\n",
    "\n",
    "        for bdry in Domain.boundaries:\n",
    "            outside_bdry = bdry.dist_to_bdry(self.Xnew) < 0\n",
    "            \n",
    "            self.Xnew[outside_bdry,:] = find_bdry_exit(self.Xold.detach().repeat(num_ghost,1)[outside_bdry,:], self.Xnew[outside_bdry,:], bdry, tol)\n",
    "        \n",
    "        self.Xnew.requires_grad=True\n",
    "        Unew = model_velocity(self.Xnew).reshape(num_ghost, numpts, output_dim).mean(0)\n",
    "        \n",
    "        ###\n",
    "        self.target = (Unew - Uold).detach()/dt\n",
    "        ### Truncate?\n",
    "        #self.target = torch.minimum(self.target, )\n",
    "        self.Xnew = self.Xnew.detach().reshape(num_ghost,numpts,x_dim)\n",
    "\n",
    "    def __len__(self):\n",
    "        ### How many data points are there?\n",
    "        return numpts\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ### Gets one sample of data\n",
    "        ### \n",
    "        return self.Xold[index,:], self.Xnew[:,index,:], self.target[index,:]\n",
    "\n",
    "### Functions\n",
    "def eval_gradient(X, model):\n",
    "    X.requires_grad = True\n",
    "    a = model(X)\n",
    "\n",
    "    grad_model = torch.autograd.grad(a, X, grad_outputs = torch.ones_like(a), create_graph = True, \n",
    "                                       retain_graph = True, only_inputs = True)[0]\n",
    "\n",
    "    return grad_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_param = {'depth': nn_depth,\n",
    "            'width': nn_width,\n",
    "            'x_dim': x_dim,\n",
    "            'is_unsteady': is_unsteady ,\n",
    "            'output_dim': output_dim\n",
    "            }\n",
    "\n",
    "eval_model_param={'dt': dt,\n",
    "                  'forcing': forcing}\n",
    "\n",
    "### Make boundaries defining the domain\n",
    "Domain = Domain(is_unsteady, boundingbox, list_of_dirichlet_boundaries, list_of_periodic_boundaries)\n",
    "\n",
    "model_velocity = torch.load(\"savedmodels/JCPexample6.pt\").to('cpu').eval()\n",
    "\n",
    "### Initialize the Model\n",
    "MyNeuralNetwork = PotentialNN\n",
    "model_pressure = MyNeuralNetwork(**nn_param).to(dev)\n",
    "\n",
    "mseloss = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.Adam(model_pressure.parameters(), \n",
    "                        lr=learning_rate, \n",
    "                        betas=adam_beta, \n",
    "                        weight_decay=weight_decay)\n",
    "\n",
    "### Create Walkers and Boundary points and Organize into DataLoader\n",
    "RWalkers = Walker_Data(boundingbox, Domain.boundaries)\n",
    "RWalkers_batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if update_walkers == 'move':\n",
    "    move_RWalkers = torch.zeros_like(RWalkers.location)\n",
    "\n",
    "###\n",
    "x_fix = torch.tensor(fix_pressure_at, dtype=torch.float, device=dev)\n",
    "p_fix = fixed_pressure*torch.ones((1), device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors in first epoch: Training will continue\n",
      "step = 1000/5000, 0.153 s/step, time-to-go:613s\n",
      "step = 2000/5000, 0.149 s/step, time-to-go:446s\n",
      "step = 3000/5000, 0.147 s/step, time-to-go:294s\n",
      "step = 4000/5000, 0.146 s/step, time-to-go:146s\n",
      "step = 5000/5000, 0.146 s/step, time-to-go: 0s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for step in range(num_epoch):\n",
    "\n",
    "    # Try fixing one point to have 0 pressure\n",
    "    #loss = lambda_fix*mseloss( model_pressure(x_fix), p_fix)\n",
    "    #loss.backward()\n",
    "\n",
    "    # Random Walkers - do in batches\n",
    "    for Xold, Xnew, target in RWalkers_batch:\n",
    "\n",
    "        # Send to GPU and set requires grad flag\n",
    "        Xold = Xold.to(dev).requires_grad_(True)\n",
    "        Xnew = Xnew.reshape(num_batch*num_ghost,x_dim).to(dev).requires_grad_(True)\n",
    "        target = target.detach().to(dev)\n",
    "\n",
    "        # No backprop wrt Xnew\n",
    "        grad_pressure = model_pressure(Xold)\n",
    "        #grad_pressure = eval_gradient(Xold, model_pressure)\n",
    "        #grad_pressure = (eval_gradient(Xold, model_pressure) + eval_gradient(Xnew, model_pressure).reshape(num_ghost, num_batch, output_dim).mean(0).detach() )/2\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = lambda_bell*mseloss(grad_pressure, target)\n",
    "        loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (step+1) % update_walkers_every == 0:\n",
    "        if update_walkers == 'remake':\n",
    "            RWalkers = DRLPDE_functions.DefineDomain.Walker_Data(boundingbox, Domain.boundaries)\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "\n",
    "    if step == 0:\n",
    "        print('No errors in first epoch: Training will continue')\n",
    "    if (step+1) % update_print_every == 0:\n",
    "        current_time = time.time()\n",
    "        np.set_printoptions(precision=2)\n",
    "        print('step = {0}/{1}, {2:2.3f} s/step, time-to-go:{3:2.0f}s'.format(\n",
    "                step+1, num_epoch, (current_time - start_time) / (step + 1), \n",
    "            (current_time - start_time) / (step + 1) * (num_epoch - step - 1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_pressure, \"savedmodels/\" + 'pressure_test'+ \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06d3ad103a38a5e5980b0a2ddf222334b9b3630c94a7e75a8e45e8afe280f469"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
