{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to learn pressure term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Learn pressure term through its gradient:\n",
    "###     Setup neural network, train through gradient\n",
    "###     - Function that evaluates gradient\n",
    "###     - Training data: Average of (Unew + Uforcing term)/dt\n",
    "###     - To lock down the constant: Need condition\n",
    "###         - Sum of pressure = 0\n",
    "###         - Pressure at a point = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import DRLPDE_nn\n",
    "import DRLPDE_functions.DefineDomain\n",
    "import DRLPDE_functions.EvaluateWalkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time step\n",
    "dt = 1e-4\n",
    "\n",
    "# exit tolerance\n",
    "tol = 1e-6\n",
    "\n",
    "# Number of walkers\n",
    "num_walkers = 2**13\n",
    "num_ghost = 256\n",
    "num_batch = 2**11\n",
    "\n",
    "# Update walkers\n",
    "# Options: \n",
    "#    move -- moves walkers to one of their new locations\n",
    "#    remake -- remake walkers at each training step\n",
    "#    fixed -- keeps walkers fixed\n",
    "update_walkers = 'move'\n",
    "update_walkers_every = 1\n",
    "\n",
    "############## Training Parameters #######################\n",
    "\n",
    "# Training epochs\n",
    "num_epoch = 1000\n",
    "update_print_every = 1000\n",
    "\n",
    "# Neural Network Architecture\n",
    "nn_depth = 20\n",
    "nn_width = 4\n",
    "\n",
    "# Weighting of losses\n",
    "lambda_bell = 1e-2/dt\n",
    "lambda_fix = 1\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1e-2\n",
    "adam_beta = (0.9,0.999)\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "    \n",
    "DRLPDE_param = importlib.import_module(\".JCPexample6\", package='examples')\n",
    "    \n",
    "### Use cuda\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "boundingbox = DRLPDE_param.boundingbox\n",
    "list_of_dirichlet_boundaries = DRLPDE_param.list_of_dirichlet_boundaries\n",
    "list_of_periodic_boundaries = DRLPDE_param.list_of_periodic_boundaries\n",
    "pde_type = DRLPDE_param.pde_type\n",
    "is_unsteady = DRLPDE_param.is_unsteady\n",
    "output_dim = DRLPDE_param.output_dim\n",
    "\n",
    "nn_param = {'depth': nn_depth,\n",
    "            'width': nn_width,\n",
    "            'x_dim':DRLPDE_param.x_dim,\n",
    "            'is_unsteady':DRLPDE_param.is_unsteady ,\n",
    "            'output_dim': 1\n",
    "            }\n",
    "            \n",
    "x_dim = DRLPDE_param.x_dim\n",
    "mu = DRLPDE_param.mu\n",
    "\n",
    "eval_model_param={'dt': dt,\n",
    "                  'forcing': DRLPDE_param.forcing}\n",
    "\n",
    "### Import functions\n",
    "\n",
    "################ Preparing the model #################\n",
    "\n",
    "#print(\"Initializing the model\")\n",
    "\n",
    "### Make boundaries defining the domain\n",
    "Domain = DRLPDE_functions.DefineDomain.Domain(is_unsteady, boundingbox, \n",
    "                                                list_of_dirichlet_boundaries,\n",
    "                                                list_of_periodic_boundaries)\n",
    "\n",
    "model_velocity = torch.load(\"savedmodels/JCPexample6.pt\")\n",
    "\n",
    "### Initialize the Model\n",
    "MyNeuralNetwork = DRLPDE_nn.FeedForwardNN\n",
    "model_pressure = MyNeuralNetwork(**nn_param).to(dev)\n",
    "\n",
    "mseloss = nn.MSELoss(reduction = 'mean')\n",
    "optimizer = optim.Adam(model_pressure.parameters(), \n",
    "                        lr=learning_rate, \n",
    "                        betas=adam_beta, \n",
    "                        weight_decay=weight_decay)\n",
    "\n",
    "### Create Walkers and Boundary points and Organize into DataLoader\n",
    "RWalkers = DRLPDE_functions.DefineDomain.Walker_Data(num_walkers, boundingbox, Domain.boundaries)\n",
    "RWalkers_batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "if update_walkers == 'move':\n",
    "    move_RWalkers = torch.zeros_like(RWalkers.location)\n",
    "\n",
    "###\n",
    "fix_pressure_at = RWalkers.location[0].to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "def eval_gradient(X, model):\n",
    "    \n",
    "    a = model(X)\n",
    "\n",
    "    grad_model = torch.autograd.grad(a, X, grad_outputs = torch.ones_like(a), create_graph = True, \n",
    "                                       retain_graph = True, only_inputs = True)[0]\n",
    "\n",
    "    return grad_model\n",
    "\n",
    "def move_Walkers(X, model, Domain, x_dim, mu, dt, num_batch, num_ghost):\n",
    "    \n",
    "    ### Evaluate model\n",
    "    Uold = model(X)\n",
    "\n",
    "    ### Move walkers\n",
    "    Zt = np.sqrt(dt)*torch.randn((num_batch*num_ghost, x_dim), device=X.device, requires_grad=True)\n",
    "    \n",
    "    Xnew = X.repeat(num_ghost,1) - dt*Uold.detach().repeat(num_ghost,1) + np.sqrt(2*mu)*Zt\n",
    "\n",
    "    ### Calculate exits\n",
    "    outside = torch.zeros( Xnew.size(0), dtype=torch.bool, device=Xnew.device)\n",
    "\n",
    "    for bdry in Domain.boundaries:\n",
    "        outside_bdry = bdry.dist_to_bdry(Xnew) < 0\n",
    "        outside += outside_bdry\n",
    "\n",
    "    return Xnew, outside[:num_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors in first epoch: Training will continue\n",
      "step = 1000/1000, 0.197 s/step, time-to-go: 0s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for step in range(num_epoch):\n",
    "\n",
    "    # Random Walkers - do in batches\n",
    "    for Xold, index in RWalkers_batch:\n",
    "\n",
    "        # Send to GPU and set requires grad flag\n",
    "        Xold = Xold.to(dev).requires_grad_(True)\n",
    "\n",
    "        # Evaluate at old location and Move walkers\n",
    "        Xnew, outside = move_Walkers(Xold, model_velocity, Domain, x_dim, mu, dt, num_batch, num_ghost)\n",
    "\n",
    "        # Evaluate at new location and average\n",
    "        Unew = model_velocity(Xnew).reshape(num_ghost, num_batch, output_dim).mean(0)\n",
    "\n",
    "        grad_pressure = eval_gradient(Xold, model_pressure)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = lambda_bell*mseloss(grad_pressure, Unew.detach()/dt)\n",
    "        loss.backward()\n",
    "\n",
    "        # If moving walkers save the first ghost walker\n",
    "        if update_walkers == 'move':\n",
    "            if any(outside):\n",
    "                Xnew[:num_batch,:][outside,:] = DRLPDE_functions.DefineDomain.generate_interior_points(torch.sum(outside), \n",
    "                                                                                            boundingbox,\n",
    "                                                                                            Domain.boundaries).to(dev)\n",
    "            move_RWalkers[index,:] = Xnew[:num_batch].detach().cpu()\n",
    "\n",
    "    # Try fixing one point to have 0 pressure\n",
    "    loss = lambda_fix*mseloss( model_pressure(fix_pressure_at), torch.zeros(1, device=dev))\n",
    "    loss.backward()\n",
    "\n",
    "    # Make optimization step\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Update walkers\n",
    "\n",
    "    if (step+1) % update_walkers_every == 0:\n",
    "        if update_walkers == 'move':\n",
    "            RWalkers.location = move_RWalkers\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "        elif update_walkers == 'remake':\n",
    "            RWalkers = DRLPDE_functions.DefineDomain.Walker_Data(num_walkers, boundingbox, Domain.boundaries)\n",
    "            RWalkers_Batch = torch.utils.data.DataLoader(RWalkers, batch_size=num_batch, shuffle=True)\n",
    "\n",
    "    if step == 0:\n",
    "        print('No errors in first epoch: Training will continue')\n",
    "    if (step+1) % update_print_every == 0:\n",
    "        current_time = time.time()\n",
    "        np.set_printoptions(precision=2)\n",
    "        print('step = {0}/{1}, {2:2.3f} s/step, time-to-go:{3:2.0f}s'.format(\n",
    "                step+1, num_epoch, (current_time - start_time) / (step + 1), \n",
    "            (current_time - start_time) / (step + 1) * (num_epoch - step - 1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_pressure, \"savedmodels/\" + 'pressure_test'+ \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f316ce05a0c4170ba4484e3efd14dee3226178e34dfd81e786ec8a894f84480"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
