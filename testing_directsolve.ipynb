{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try using a neural network to learn a function just from random space points and the exact value\n",
    "### See how the error goes down as the runtime, size of network, methodology change\n",
    "\n",
    "# Solution to Laplace's equation\n",
    "# u(x,y) = 4.0*(x - 1.0)**2 - 4.0*(y + 0.5)**2\n",
    "#  in a polar region r = 0.75*cos(theta) + 1.1\n",
    "#  Compare PDE solver with Direct solver\n",
    "\n",
    "# High frequency \n",
    "# u(x,y) = sin( 4.2*x ) cos( 7.4*y).^2\n",
    "\n",
    "# Radial function\n",
    "# u(x,y) = sin( sqrt(x^2 + y^2) )\n",
    "\n",
    "# High dimensional d=50\n",
    "# u(x1, ..., x50) =\n",
    "\n",
    "# Peaks\n",
    "#  z = 3*(1-x).^2.*exp(-(x.^2) - (y+1).^2) - 10*(x/5 - x.^3 - y.^5).*exp(-x.^2-y.^2) - 1/3*exp(-(x+1).^2 - y.^2) \n",
    "\n",
    "# Franke's function\n",
    "# z = 3/4 * e^(- ( (9x - 2)^2 + (9y -2)^2 )/4 ) + 3/4 * e^( -( (9x-1)^2/49 - (9y+1)/10 )) + 1/2 * e^( -( (9x-7)^2 + (9y-3)^2 )/4 ) - 1/5 * e^( -(  (9x-4)^2 + (9y-7)^2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import DRLPDE.create as create\n",
    "import DRLPDE.neuralnets as neuralnets\n",
    "import DRLPDE.train as train\n",
    "import DRLPDE.solver as solver\n",
    "import DRLPDE.main as main\n",
    "import DRLPDE.diagnostics as diagnostics\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "use_cuda=torch.cuda.is_available()\n",
    "dev = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = 'example1'\n",
    "solver = {'savemodel':'Test_SeparateOptimizers', \n",
    "         'trainingsteps':100,\n",
    "         'method':{'type':'direct'},\n",
    "         'optimizer':{'learningrate': 1e-4,\n",
    "                'beta': (0.9, 0.999),\n",
    "                'weightdecay': 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "### Parameters of the Problem\n",
    "\n",
    "if parameters:\n",
    "    param = importlib.import_module(\".\" + parameters, package='examples')\n",
    "    problem = 'examples/' + parameters + '.py'\n",
    "else:\n",
    "    import DRLPDE.parameters as param\n",
    "    problem = 'default_parameters.py'\n",
    "\n",
    "# Dimensions of problem\n",
    "input_dim = [param.x_dim, param.t_dim, param.hyper_dim]\n",
    "\n",
    "output_dim = param.output_dim\n",
    "\n",
    "# Intervals\n",
    "input_range = param.boundingbox + param.t_range + param.hyper_range\n",
    "\n",
    "# Boolean for each wall type\n",
    "there_are_walls = any(param.list_of_walls)\n",
    "there_are_solids = any(param.solid_walls)\n",
    "there_are_inletoutlets = any(param.inlet_outlet)\n",
    "there_are_meshes = any(param.mesh)\n",
    "unsteady = bool(param.t_dim)\n",
    "\n",
    "# Diagnostics \n",
    "collect_error = param.collect_error\n",
    "if collect_error:\n",
    "    num_error = param.num_error\n",
    "    true_fun = param.true_fun\n",
    "\n",
    "solver_parameters = main.define_solver_parameters(problem, **solver)\n",
    "\n",
    "# Training parameters\n",
    "trainingsteps = int(solver_parameters['trainingsteps'])\n",
    "num = solver_parameters['numpts']\n",
    "numbatch = solver_parameters['numbatch']\n",
    "resample_every = solver_parameters['resample_every']\n",
    "walk = solver_parameters['walk']\n",
    "importance_sampling = solver_parameters['importance_sampling']\n",
    "reweight_every = solver_parameters['adaptive_weighting']['reweight_every']\n",
    "stepsize = solver_parameters['adaptive_weighting']['stepsize']\n",
    "print_every = round(trainingsteps/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the Neural Network\n",
    "\n",
    "# TODO: Choose other neural network architectures from neuralnets.py\n",
    "if solver_parameters['neuralnetwork'] == 'FeedForward':\n",
    "    MyNeuralNetwork = neuralnets.FeedForwardNN\n",
    "elif solver_parameters['neuralnetwork'] == 'Incompressible':\n",
    "    MyNeuralNetwork = neuralnets.IncompressibleNN\n",
    "\n",
    "nn_size = solver_parameters['nn_size']\n",
    "\n",
    "model = MyNeuralNetwork(input_dim, output_dim, **nn_size).to(dev)\n",
    "    \n",
    "optimizer1 = torch.optim.Adam(model.parameters(), \n",
    "                                lr=solver_parameters['optimizer']['learningrate'], \n",
    "                                betas=solver_parameters['optimizer']['beta'], \n",
    "                                weight_decay=solver_parameters['optimizer']['weightdecay'])\n",
    "\n",
    "optimizer2 = torch.optim.Adam(model.parameters(), \n",
    "                                lr=solver_parameters['optimizer']['learningrate'], \n",
    "                                betas=solver_parameters['optimizer']['beta'], \n",
    "                                weight_decay=solver_parameters['optimizer']['weightdecay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Physical domain through its boundaries\n",
    "Domain = create.SpaceDomain(param.boundingbox, \n",
    "                            param.list_of_walls, \n",
    "                            param.solid_walls, \n",
    "                            param.inlet_outlet, \n",
    "                            param.list_of_periodic_ends, \n",
    "                            param.mesh)\n",
    "\n",
    "wall_measure = Domain.wall[0].measure\n",
    "\n",
    "# Create Interior points and organize into batches\n",
    "IntPoints = create.InteriorPoints(num, Domain, input_dim, input_range)\n",
    "IntPoints_batch = torch.utils.data.DataLoader(IntPoints, batch_size=numbatch, shuffle=True)\n",
    "\n",
    "# Create Dirichlet Wall points and organize into batches\n",
    "num_wall = create.numBCpoints(num, input_dim, Domain, Domain.wall)\n",
    "BCPoints = create.BCPoints(num_wall, Domain, input_dim, input_range)\n",
    "BCPoints_batch = torch.utils.data.DataLoader(BCPoints, batch_size=numbatch, shuffle=True)\n",
    "\n",
    "### Random points for calculating L2 error through Monte Carlo Integration\n",
    "ErrorPoints = create.InteriorPoints(num_error, Domain, input_dim, input_range)\n",
    "ErrorPoints_batch = torch.utils.data.DataLoader(ErrorPoints, batch_size=numbatch, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver_parameters['method']['type']\n",
    "### Method type\n",
    "if solver_parameters['method']['type'] == 'autodiff':\n",
    "    import DRLPDE.autodiff as method\n",
    "    var_train = {'diffusion': param.diffusion,\n",
    "                    'forcing': param.forcing,\n",
    "                    'x_dim': input_dim[0]\n",
    "                }\n",
    "    \n",
    "        ### PDE\n",
    "    if unsteady:\n",
    "        if param.pde_type == 'NavierStokes':\n",
    "            make_target = method.unsteadyNavierStokes\n",
    "        elif param.pde_type == 'viscousBurgers':\n",
    "            make_target = method.unsteadyViscousBurgers\n",
    "    else:\n",
    "        if param.pde_type == 'NavierStokes':\n",
    "            make_target = method.steadyNavierStokes\n",
    "        elif param.pde_type == 'viscousBurgers':\n",
    "            make_target = method.steadyViscousBurgers\n",
    "        elif param.pde_type == 'Stokes':\n",
    "            make_target = method.Laplace\n",
    "        elif param.pde_type == 'Laplace':\n",
    "            make_target = method.Laplace\n",
    "\n",
    "elif solver_parameters['method']['type'] == 'stochastic':\n",
    "    import DRLPDE.stochastic as method\n",
    "    var_train = {'diffusion': param.diffusion,\n",
    "                'forcing': param.forcing, \n",
    "                'x_dim': input_dim[0],\n",
    "                'domain': Domain,\n",
    "                'dt': solver_parameters['method']['dt'],\n",
    "                'num_ghost': solver_parameters['method']['num_ghost'], \n",
    "                'tol': solver_parameters['method']['tol']\n",
    "                }\n",
    "\n",
    "    ### PDE\n",
    "    if unsteady:\n",
    "        var_train['ic'] = param.init_con\n",
    "        if param.pde_type == 'NavierStokes':\n",
    "            make_target = method.unsteadyNavierStokes\n",
    "        elif param.pde_type == 'viscousBurgers':\n",
    "            make_target = method.unsteadyViscousBurgers\n",
    "        elif param.pde_type == 'Stokes':\n",
    "            make_target = method.Heat\n",
    "        elif param.pde_type == 'Heat':\n",
    "            make_target = method.Heat\n",
    "    else:\n",
    "        if param.pde_type == 'NavierStokes':\n",
    "            make_target = method.steadyNavierStokes\n",
    "        elif param.pde_type == 'viscousBurgers':\n",
    "            make_target = method.steadyViscousBurgers\n",
    "        elif param.pde_type == 'Stokes':\n",
    "            make_target = method.Laplace\n",
    "        elif param.pde_type == 'Laplace':\n",
    "            make_target = method.Laplace\n",
    "\n",
    "elif solver_parameters['method']['type'] == 'direct':\n",
    "    var_train = {'true_fun': param.true_fun}\n",
    "    make_target = train.Direct_target\n",
    "    \n",
    "elif solver.method == 'finitediff':\n",
    "    pass\n",
    "    # import finitediff as method\n",
    "    # var_train = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors in first epoch, training will continue\n"
     ]
    }
   ],
   "source": [
    "# Interior\n",
    "optimizer1.zero_grad()\n",
    "L2loss_interior, Linfloss_interior, resample_interior = train.interior(IntPoints_batch, num, model, make_target, var_train, dev, Domain.volume, 1.0, 0.0, False)\n",
    "optimizer1.step()\n",
    "\n",
    "Total_L2loss_interior = L2loss_interior.cpu().numpy()*np.ones(trainingsteps)\n",
    "Total_Linfloss_interior = Linfloss_interior.cpu().numpy()*np.ones(trainingsteps)\n",
    "\n",
    "# Walls\n",
    "optimizer2.zero_grad()\n",
    "L2loss_wall, Linfloss_wall, resample_wall = train.boundary(BCPoints_batch, num_wall, model, train.Dirichlet_target, dev, wall_measure, 0.0, False)\n",
    "optimizer2.step()\n",
    "\n",
    "Total_L2loss_wall = L2loss_wall.cpu().numpy()*np.ones(trainingsteps)\n",
    "Total_Linfloss_wall = Linfloss_wall.cpu().numpy()*np.ones(trainingsteps)\n",
    "\n",
    "# Collect Errors\n",
    "ErrorPoints.location = create.generate_interior_points(num_error, input_dim, input_range, Domain, Domain.inside)\n",
    "L2error, Linferror = diagnostics.CalculateError(ErrorPoints_batch, num_error, Domain.volume, model, true_fun, dev)\n",
    "\n",
    "Total_L2error = L2error.cpu().numpy()*np.ones(trainingsteps)\n",
    "Total_Linferror = Linferror.cpu().numpy()*np.ones(trainingsteps)\n",
    "\n",
    "print('No errors in first epoch, training will continue')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx time: 0 minutes\n",
      "step = 10/100, 0.204 s/step, time-to-go: 0 min\n",
      "step = 20/100, 0.204 s/step, time-to-go: 0 min\n",
      "step = 30/100, 0.202 s/step, time-to-go: 0 min\n",
      "step = 40/100, 0.202 s/step, time-to-go: 0 min\n",
      "step = 50/100, 0.203 s/step, time-to-go: 0 min\n",
      "step = 60/100, 0.204 s/step, time-to-go: 0 min\n",
      "step = 70/100, 0.205 s/step, time-to-go: 0 min\n",
      "step = 80/100, 0.205 s/step, time-to-go: 0 min\n",
      "step = 90/100, 0.205 s/step, time-to-go: 0 min\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### Continue training\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for step in range(trainingsteps-1):\n",
    "    \n",
    "    # Interior\n",
    "    optimizer1.zero_grad()\n",
    "    L2loss_interior, Linfloss_interior, resample_interior = train.interior(IntPoints_batch, num, model, make_target, var_train, dev, Domain.volume, 1.0, 0.0, False)\n",
    "    optimizer1.step()\n",
    "\n",
    "    Total_L2loss_interior[step+1] = L2loss_interior.cpu().numpy()\n",
    "    Total_Linfloss_interior[step+1] = Linfloss_interior.cpu().numpy()\n",
    "\n",
    "    # Wall\n",
    "    optimizer2.zero_grad()\n",
    "    L2loss_wall, Linfloss_wall, resample_wall = train.boundary(BCPoints_batch, num_wall, model, train.Dirichlet_target, dev, wall_measure, 0.0, False)\n",
    "    optimizer2.step()\n",
    "\n",
    "    Total_L2loss_wall[step+1] = L2loss_wall.cpu().numpy()\n",
    "    Total_Linfloss_wall[step+1] = Linfloss_wall.cpu().numpy()\n",
    "\n",
    "    # Collect Errors\n",
    "    ErrorPoints.location = create.generate_interior_points(num_error, input_dim, input_range, Domain, Domain.inside)\n",
    "    L2error, Linferror = diagnostics.CalculateError(ErrorPoints_batch, num_error, Domain.volume, model, true_fun,dev)\n",
    "\n",
    "    Total_L2error[step+1] = L2error.cpu().numpy()\n",
    "    Total_Linferror[step+1] = Linferror.cpu().numpy()\n",
    "\n",
    "    # Print statements\n",
    "    if step == 0:\n",
    "        current_time = time.time()\n",
    "        print('Approx time: {:.0f} minutes'.format((current_time - start_time)*trainingsteps/60))\n",
    "\n",
    "    if (step+1) % print_every == 0:\n",
    "        current_time = time.time()\n",
    "        print('step = {0}/{1}, {2:2.3f} s/step, time-to-go:{3:2.0f} min'.format(\n",
    "                step+1, trainingsteps, (current_time - start_time) / (step + 1), \n",
    "            (current_time - start_time) / (step + 1) * (trainingsteps - step - 1)/60))\n",
    "\n",
    "### Final errors\n",
    "loss_error = {'loss' : {}, 'errors': {}}\n",
    "loss_error['loss']['L2 interior loss'] = Total_L2loss_interior\n",
    "loss_error['loss']['Linf interior loss'] = Total_Linfloss_interior\n",
    "\n",
    "loss_error['loss']['L2 wall loss'] = Total_L2loss_wall\n",
    "loss_error['loss']['Linf wall loss'] = Total_Linfloss_wall\n",
    "\n",
    "loss_error['errors']['L2 error'] = Total_L2error\n",
    "loss_error['errors']['Linf error'] = Total_Linferror\n",
    "\n",
    "### Save as pickle file\n",
    "\n",
    "with open('experiments/' + solver_parameters['savemodel'] + '_losserror.pickle', 'wb' ) as handle:\n",
    "    pickle.dump(loss_error, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('experiments/' + solver_parameters['savemodel'] + '_parameters.pickle', 'wb') as handle:\n",
    "    pickle.dump(solver_parameters, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"savedmodels/\" + solver_parameters['savemodel'] + \".pt\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mskpark/Research/DRLPDE/testing_directsolve.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/testing_directsolve.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m4\u001b[39m}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/testing_directsolve.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m test_dict[\u001b[39m'\u001b[39;49m\u001b[39mc\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/testing_directsolve.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCan check for item in dictionary\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mskpark/Research/DRLPDE/testing_directsolve.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c'"
     ]
    }
   ],
   "source": [
    "test_dict = {'a':2, 'b':4}\n",
    "\n",
    "if test_dict['c']:\n",
    "    print('Can check for item in dictionary')\n",
    "else:\n",
    "    print('Does not work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
